{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業重點:\n",
    "\n",
    "(1)以, Adam, 為例, 調整 batch_size, epoch , 觀察accurancy, loss 的變化\n",
    "\n",
    "(2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業目標:\n",
    "    \n",
    "    取得各種優化器的運算結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n",
    "# import tensorflow.compat.v1 as tfv1\n",
    "# gpu_options = tfv1.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tfv1.Session(config=tfv1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   宣告並設定\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs ：訓練次數\n",
    "'''\n",
    "# epochs = 20\n",
    "# batch_size = 32\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "num_classes = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    第一步：選擇模型, 順序模型是多個網絡層的線性堆疊\n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "#   第二步：構建網絡層\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense( 10)) # 輸出結果是10個類別，所以維度是10   \n",
    "model.add(Activation('softmax')) # 最後一層用softmax作為激活函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters：1250858\n"
     ]
    }
   ],
   "source": [
    "# 模型建立完成後，統計參數總量\n",
    "print(\"Total Parameters：%d\" % model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 輸出模型摘要資訊\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第三步編譯\n",
    "'''\n",
    " SGD(隨機梯度下降) - Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "'''\n",
    "\n",
    "'''\n",
    "RMSprop- Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "rho: float >= 0.\n",
    "epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "'''\n",
    "\n",
    "\n",
    "opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# (2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy\n",
    "\n",
    "# model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.compile(optimizer = 'SGD', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料正規化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history=model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        print('')\n",
    "\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "            width_shift_range=0.1,\n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.,  # set range for random shear\n",
    "            zoom_range=0.,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function=None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            validation_split=0.0)\n",
    "\n",
    "        # Compute quantities required for feature-wise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "        history=model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True)   \n",
    "\n",
    "# \n",
    "#    第四步：訓練\n",
    "#    .fit的一些參數\n",
    "#    batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "#    epochs ：訓練次數\n",
    "#    shuffle：是否把數據隨機打亂之後再進行訓練\n",
    "#    validation_split：拿出百分之多少用來做交叉驗證\n",
    "#    verbose：屏顯模式 - 0：不輸出, 1：輸出進度, 2：輸出每次的訓練結果\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\sychen\\Desktop\\ipython\\ml100\\D76\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "Using real-time data augmentation.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 2.0027 - accuracy: 0.2592 - val_loss: 1.7034 - val_accuracy: 0.3973\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.6229 - accuracy: 0.4065 - val_loss: 1.4397 - val_accuracy: 0.4862\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.4062 - accuracy: 0.4873 - val_loss: 1.2390 - val_accuracy: 0.5512\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.2823 - accuracy: 0.5402 - val_loss: 1.1495 - val_accuracy: 0.5903\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 1.1908 - accuracy: 0.5746 - val_loss: 1.0543 - val_accuracy: 0.6238\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.1144 - accuracy: 0.6041 - val_loss: 0.9888 - val_accuracy: 0.6456\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 1.0490 - accuracy: 0.6280 - val_loss: 0.9304 - val_accuracy: 0.6688\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.9966 - accuracy: 0.6469 - val_loss: 0.9064 - val_accuracy: 0.6824\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.9545 - accuracy: 0.6629 - val_loss: 0.8758 - val_accuracy: 0.6949\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 0.9100 - accuracy: 0.6790 - val_loss: 0.8458 - val_accuracy: 0.7021\n",
      "10000/10000 [==============================] - 1s 123us/step\n",
      "SGD loss: 0.8457861577033997\n",
      "SGD accuracy: 0.7020999789237976\n",
      "Using real-time data augmentation.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.8654 - accuracy: 0.6926 - val_loss: 0.7969 - val_accuracy: 0.7247\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.8343 - accuracy: 0.7052 - val_loss: 0.7579 - val_accuracy: 0.7342\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.8021 - accuracy: 0.7149 - val_loss: 0.7538 - val_accuracy: 0.7376\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.7713 - accuracy: 0.7268 - val_loss: 0.7295 - val_accuracy: 0.7448\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 0.7417 - accuracy: 0.7378 - val_loss: 0.7188 - val_accuracy: 0.7508\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.7210 - accuracy: 0.7435 - val_loss: 0.7114 - val_accuracy: 0.7528\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.6965 - accuracy: 0.7543 - val_loss: 0.6733 - val_accuracy: 0.7672\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 0.6716 - accuracy: 0.7616 - val_loss: 0.6742 - val_accuracy: 0.7671\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.6477 - accuracy: 0.7716 - val_loss: 0.6510 - val_accuracy: 0.7718\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 0.6368 - accuracy: 0.7751 - val_loss: 0.6504 - val_accuracy: 0.7730\n",
      "10000/10000 [==============================] - 1s 114us/step\n",
      "Adam loss: 0.6503753083705902\n",
      "Adam accuracy: 0.7730000019073486\n",
      "Using real-time data augmentation.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.6109 - accuracy: 0.7822 - val_loss: 0.6418 - val_accuracy: 0.7777\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.5962 - accuracy: 0.7880 - val_loss: 0.6294 - val_accuracy: 0.7825\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.5718 - accuracy: 0.7960 - val_loss: 0.6399 - val_accuracy: 0.7794\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 0.5623 - accuracy: 0.7991 - val_loss: 0.6183 - val_accuracy: 0.7860\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 0.5416 - accuracy: 0.8087 - val_loss: 0.6287 - val_accuracy: 0.7806\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.5278 - accuracy: 0.8116 - val_loss: 0.6153 - val_accuracy: 0.7919\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.5131 - accuracy: 0.8175 - val_loss: 0.6124 - val_accuracy: 0.7881\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 0.5032 - accuracy: 0.8209 - val_loss: 0.6000 - val_accuracy: 0.7952\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.4861 - accuracy: 0.8267 - val_loss: 0.6094 - val_accuracy: 0.7955\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.4786 - accuracy: 0.8294 - val_loss: 0.6362 - val_accuracy: 0.7844\n",
      "10000/10000 [==============================] - 1s 114us/step\n",
      "RMSprop loss: 0.6361796167850494\n",
      "RMSprop accuracy: 0.7843999862670898\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "train_model()\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('SGD loss:', scores[0])\n",
    "print('SGD accuracy:', scores[1])\n",
    "\n",
    "# Score trained model.\n",
    "train_model()\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Adam loss:', scores[0])\n",
    "print('Adam accuracy:', scores[1])\n",
    "\n",
    "# Score trained model.\n",
    "train_model()\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('RMSprop loss:', scores[0])\n",
    "print('RMSprop accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test set \n",
      "\n",
      " The test loss is %f  [0.6361796075105667, 0.7843999862670898]\n"
     ]
    }
   ],
   "source": [
    "#    第六步：輸出\n",
    "import numpy \n",
    "\n",
    "print ( \" test set \" )\n",
    "scores = model.evaluate(x_test,y_test,batch_size=200,verbose= 0)\n",
    "print ( \"\" )\n",
    "print ( \" The test loss is %f \", scores)\n",
    "\n",
    "\n",
    "result = model.predict(x_test,batch_size=200,verbose= 0)\n",
    "\n",
    "result_max = numpy.argmax(result, axis = 1 )\n",
    "test_max = numpy.argmax(y_test, axis = 1 )\n",
    "\n",
    "result_bool = numpy.equal(result_max, test_max)\n",
    "true_num = numpy.sum(result_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-bac46b99209b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-bac46b99209b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    history = global history\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "global history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7858d657a216>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Plot training & validation accuracy values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valiidation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valiidation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
