{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
    "### 常見的 optimizer 包含\n",
    "* SGD\n",
    "* RMSprop\n",
    "* AdaGrad\n",
    "* Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        print(n_units)\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation='relu', name='hidden_layer'+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation='relu', name='hidden_layer'+str(i+1))(x)\n",
    "    output = keras.layers.Dense(units=output_units, activation='softmax', name='output')(x)\n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "# 比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = [1e-1, 1e-2, 1e-3]\n",
    "EPOCHS = 50\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000 & OPT = SGD\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 2.0548 - accuracy: 0.2397 - val_loss: 1.8013 - val_accuracy: 0.3484\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.7754 - accuracy: 0.3604 - val_loss: 1.8387 - val_accuracy: 0.3143\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.7478 - accuracy: 0.3708 - val_loss: 1.6927 - val_accuracy: 0.3921\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.7046 - accuracy: 0.3910 - val_loss: 1.8294 - val_accuracy: 0.3669\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6694 - accuracy: 0.4025 - val_loss: 1.7062 - val_accuracy: 0.4005\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.6489 - accuracy: 0.4097 - val_loss: 1.6634 - val_accuracy: 0.4074\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6321 - accuracy: 0.4186 - val_loss: 1.6670 - val_accuracy: 0.3954\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.6194 - accuracy: 0.4222 - val_loss: 1.6373 - val_accuracy: 0.4085\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6213 - accuracy: 0.4204 - val_loss: 1.6296 - val_accuracy: 0.4170\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5989 - accuracy: 0.4311 - val_loss: 1.8427 - val_accuracy: 0.3639\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5951 - accuracy: 0.4306 - val_loss: 1.6667 - val_accuracy: 0.4126\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5850 - accuracy: 0.4338 - val_loss: 1.6853 - val_accuracy: 0.3944\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5912 - accuracy: 0.4322 - val_loss: 1.7022 - val_accuracy: 0.4015\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5794 - accuracy: 0.4400 - val_loss: 1.6968 - val_accuracy: 0.4079\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5664 - accuracy: 0.4436 - val_loss: 1.6612 - val_accuracy: 0.4145\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.5627 - accuracy: 0.4443 - val_loss: 1.7189 - val_accuracy: 0.4116\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5500 - accuracy: 0.4486 - val_loss: 1.6522 - val_accuracy: 0.4135\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.5414 - accuracy: 0.4542 - val_loss: 1.7212 - val_accuracy: 0.3915\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5336 - accuracy: 0.4556 - val_loss: 1.7046 - val_accuracy: 0.3907\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5341 - accuracy: 0.4545 - val_loss: 1.6879 - val_accuracy: 0.4019\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5346 - accuracy: 0.4558 - val_loss: 1.6648 - val_accuracy: 0.4297\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5262 - accuracy: 0.4569 - val_loss: 1.7091 - val_accuracy: 0.4154\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5185 - accuracy: 0.4628 - val_loss: 1.7150 - val_accuracy: 0.4040\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5243 - accuracy: 0.4609 - val_loss: 1.7151 - val_accuracy: 0.3972\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.5164 - accuracy: 0.4643 - val_loss: 1.6229 - val_accuracy: 0.4241\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5116 - accuracy: 0.4649 - val_loss: 1.6900 - val_accuracy: 0.4181\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5049 - accuracy: 0.4684 - val_loss: 1.6155 - val_accuracy: 0.4285\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4965 - accuracy: 0.4725 - val_loss: 1.6372 - val_accuracy: 0.4305\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5007 - accuracy: 0.4678 - val_loss: 1.6281 - val_accuracy: 0.4308\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.4910 - accuracy: 0.4737 - val_loss: 1.6555 - val_accuracy: 0.4095\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.4794 - accuracy: 0.4747 - val_loss: 1.6506 - val_accuracy: 0.4195\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.4855 - accuracy: 0.4773 - val_loss: 1.6760 - val_accuracy: 0.4213\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4841 - accuracy: 0.4807 - val_loss: 1.6116 - val_accuracy: 0.4483\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4693 - accuracy: 0.4841 - val_loss: 1.6436 - val_accuracy: 0.4262\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4699 - accuracy: 0.4819 - val_loss: 1.5864 - val_accuracy: 0.4463\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4621 - accuracy: 0.4861 - val_loss: 1.6392 - val_accuracy: 0.4400\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4722 - accuracy: 0.4826 - val_loss: 1.6530 - val_accuracy: 0.4241\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4700 - accuracy: 0.4835 - val_loss: 1.7156 - val_accuracy: 0.4150\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4499 - accuracy: 0.4895 - val_loss: 1.6069 - val_accuracy: 0.4380\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.4458 - accuracy: 0.4927 - val_loss: 1.6778 - val_accuracy: 0.4256\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4503 - accuracy: 0.4909 - val_loss: 1.7459 - val_accuracy: 0.4119\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4508 - accuracy: 0.4893 - val_loss: 1.6303 - val_accuracy: 0.4327\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4487 - accuracy: 0.4888 - val_loss: 1.6779 - val_accuracy: 0.4461\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4294 - accuracy: 0.5005 - val_loss: 1.6761 - val_accuracy: 0.4369\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.4336 - accuracy: 0.4963 - val_loss: 1.6614 - val_accuracy: 0.4347\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4328 - accuracy: 0.4973 - val_loss: 1.6459 - val_accuracy: 0.4400\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4310 - accuracy: 0.5005 - val_loss: 1.5867 - val_accuracy: 0.4534\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4230 - accuracy: 0.5027 - val_loss: 1.6696 - val_accuracy: 0.4253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4144 - accuracy: 0.5029 - val_loss: 1.6791 - val_accuracy: 0.4321\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4218 - accuracy: 0.5019 - val_loss: 1.7200 - val_accuracy: 0.4243\n",
      "Experiment with LR = 0.010000 & OPT = SGD\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8212 - accuracy: 0.3488 - val_loss: 1.7862 - val_accuracy: 0.3476\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5982 - accuracy: 0.4324 - val_loss: 1.5590 - val_accuracy: 0.4473\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.5016 - accuracy: 0.4650 - val_loss: 1.6385 - val_accuracy: 0.4202\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.4435 - accuracy: 0.4856 - val_loss: 1.5668 - val_accuracy: 0.4639\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3937 - accuracy: 0.5025 - val_loss: 1.4294 - val_accuracy: 0.4844\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.3619 - accuracy: 0.5179 - val_loss: 1.4032 - val_accuracy: 0.5020\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3229 - accuracy: 0.5301 - val_loss: 1.3899 - val_accuracy: 0.5071\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2871 - accuracy: 0.5423 - val_loss: 1.3837 - val_accuracy: 0.5113\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.2536 - accuracy: 0.5558 - val_loss: 1.4596 - val_accuracy: 0.4836\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.2280 - accuracy: 0.5638 - val_loss: 1.3368 - val_accuracy: 0.5235\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1959 - accuracy: 0.5768 - val_loss: 1.3370 - val_accuracy: 0.5263\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.1671 - accuracy: 0.5841 - val_loss: 1.3516 - val_accuracy: 0.5227\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.1373 - accuracy: 0.5956 - val_loss: 1.3769 - val_accuracy: 0.5164\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.1150 - accuracy: 0.6024 - val_loss: 1.3418 - val_accuracy: 0.5388\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.0900 - accuracy: 0.6138 - val_loss: 1.3845 - val_accuracy: 0.5235\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0657 - accuracy: 0.6194 - val_loss: 1.3915 - val_accuracy: 0.5142\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0475 - accuracy: 0.6258 - val_loss: 1.4056 - val_accuracy: 0.5186\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0112 - accuracy: 0.6397 - val_loss: 1.4240 - val_accuracy: 0.5194\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.9936 - accuracy: 0.6454 - val_loss: 1.3437 - val_accuracy: 0.5434\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.9640 - accuracy: 0.6552 - val_loss: 1.4228 - val_accuracy: 0.5187\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.9418 - accuracy: 0.6637 - val_loss: 1.5023 - val_accuracy: 0.5135\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.9231 - accuracy: 0.6707 - val_loss: 1.3813 - val_accuracy: 0.5368\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.8863 - accuracy: 0.6842 - val_loss: 1.5034 - val_accuracy: 0.5225\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.8693 - accuracy: 0.6900 - val_loss: 1.4542 - val_accuracy: 0.5215\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.8462 - accuracy: 0.6957 - val_loss: 1.4627 - val_accuracy: 0.5288\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.8155 - accuracy: 0.7084 - val_loss: 1.4772 - val_accuracy: 0.5331\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.7943 - accuracy: 0.7150 - val_loss: 1.4974 - val_accuracy: 0.5349\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.7700 - accuracy: 0.7264 - val_loss: 1.5393 - val_accuracy: 0.5385\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.7477 - accuracy: 0.7312 - val_loss: 1.6267 - val_accuracy: 0.5161\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.7280 - accuracy: 0.7380 - val_loss: 1.5496 - val_accuracy: 0.5268\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.7027 - accuracy: 0.7497 - val_loss: 1.5229 - val_accuracy: 0.5410\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.6821 - accuracy: 0.7573 - val_loss: 1.5796 - val_accuracy: 0.5234\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.6611 - accuracy: 0.7639 - val_loss: 1.5893 - val_accuracy: 0.5329\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.6283 - accuracy: 0.7748 - val_loss: 1.6610 - val_accuracy: 0.5387\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.6091 - accuracy: 0.7826 - val_loss: 1.6917 - val_accuracy: 0.5354\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.5960 - accuracy: 0.7883 - val_loss: 1.7517 - val_accuracy: 0.5216\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.5690 - accuracy: 0.7969 - val_loss: 1.7508 - val_accuracy: 0.5313\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.5643 - accuracy: 0.7980 - val_loss: 1.8632 - val_accuracy: 0.5236\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.5391 - accuracy: 0.8081 - val_loss: 1.8398 - val_accuracy: 0.5361\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.5218 - accuracy: 0.8136 - val_loss: 1.8525 - val_accuracy: 0.5367\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.4944 - accuracy: 0.8211 - val_loss: 1.8968 - val_accuracy: 0.5266\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.4844 - accuracy: 0.8254 - val_loss: 1.9612 - val_accuracy: 0.5244\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.4702 - accuracy: 0.8331 - val_loss: 1.9511 - val_accuracy: 0.5266\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.4429 - accuracy: 0.8398 - val_loss: 2.0733 - val_accuracy: 0.5173\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.4302 - accuracy: 0.8459 - val_loss: 2.0906 - val_accuracy: 0.5268\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.4242 - accuracy: 0.8492 - val_loss: 2.1690 - val_accuracy: 0.5208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.3914 - accuracy: 0.8599 - val_loss: 2.2098 - val_accuracy: 0.5220\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.3898 - accuracy: 0.8612 - val_loss: 2.2653 - val_accuracy: 0.5094\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.3796 - accuracy: 0.8632 - val_loss: 2.2405 - val_accuracy: 0.5260\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.3734 - accuracy: 0.8659 - val_loss: 2.3071 - val_accuracy: 0.5243\n",
      "Experiment with LR = 0.001000 & OPT = SGD\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.0306 - accuracy: 0.2726 - val_loss: 1.8592 - val_accuracy: 0.3443\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.7985 - accuracy: 0.3674 - val_loss: 1.7490 - val_accuracy: 0.3820\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.7150 - accuracy: 0.3993 - val_loss: 1.6817 - val_accuracy: 0.4079\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6569 - accuracy: 0.4186 - val_loss: 1.6340 - val_accuracy: 0.4262\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6094 - accuracy: 0.4352 - val_loss: 1.5946 - val_accuracy: 0.4418\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.5715 - accuracy: 0.4484 - val_loss: 1.5751 - val_accuracy: 0.4480\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5361 - accuracy: 0.4595 - val_loss: 1.5362 - val_accuracy: 0.4583\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5069 - accuracy: 0.4706 - val_loss: 1.5182 - val_accuracy: 0.4639\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.4789 - accuracy: 0.4784 - val_loss: 1.5314 - val_accuracy: 0.4649\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4560 - accuracy: 0.4901 - val_loss: 1.4681 - val_accuracy: 0.4790\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4326 - accuracy: 0.4963 - val_loss: 1.4565 - val_accuracy: 0.4888\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.4095 - accuracy: 0.5034 - val_loss: 1.4390 - val_accuracy: 0.4860\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3866 - accuracy: 0.5114 - val_loss: 1.4237 - val_accuracy: 0.4952\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3696 - accuracy: 0.5184 - val_loss: 1.4360 - val_accuracy: 0.4900\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3516 - accuracy: 0.5234 - val_loss: 1.4168 - val_accuracy: 0.4942\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.3325 - accuracy: 0.5296 - val_loss: 1.4015 - val_accuracy: 0.5035\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.3142 - accuracy: 0.5371 - val_loss: 1.4086 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.2975 - accuracy: 0.5432 - val_loss: 1.3787 - val_accuracy: 0.5098\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.2820 - accuracy: 0.5487 - val_loss: 1.3723 - val_accuracy: 0.5106\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.2664 - accuracy: 0.5535 - val_loss: 1.3937 - val_accuracy: 0.5087\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.2522 - accuracy: 0.5587 - val_loss: 1.3778 - val_accuracy: 0.5078\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.2365 - accuracy: 0.5654 - val_loss: 1.3973 - val_accuracy: 0.5022\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.2207 - accuracy: 0.5694 - val_loss: 1.3696 - val_accuracy: 0.5144\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.2076 - accuracy: 0.5744 - val_loss: 1.3580 - val_accuracy: 0.5163\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.1948 - accuracy: 0.5788 - val_loss: 1.3593 - val_accuracy: 0.5184\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1792 - accuracy: 0.5849 - val_loss: 1.3432 - val_accuracy: 0.5179\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1663 - accuracy: 0.5891 - val_loss: 1.3554 - val_accuracy: 0.5172\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1519 - accuracy: 0.5945 - val_loss: 1.3344 - val_accuracy: 0.5308\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1379 - accuracy: 0.6002 - val_loss: 1.3701 - val_accuracy: 0.5188\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1279 - accuracy: 0.6019 - val_loss: 1.3952 - val_accuracy: 0.5074\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.1122 - accuracy: 0.6111 - val_loss: 1.3550 - val_accuracy: 0.5248\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0980 - accuracy: 0.6124 - val_loss: 1.3373 - val_accuracy: 0.5285\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0857 - accuracy: 0.6197 - val_loss: 1.3622 - val_accuracy: 0.5176\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0743 - accuracy: 0.6229 - val_loss: 1.3510 - val_accuracy: 0.5246\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0632 - accuracy: 0.6251 - val_loss: 1.3820 - val_accuracy: 0.5166\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0465 - accuracy: 0.6325 - val_loss: 1.3856 - val_accuracy: 0.5115\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0380 - accuracy: 0.6369 - val_loss: 1.3423 - val_accuracy: 0.5295\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.0226 - accuracy: 0.6396 - val_loss: 1.3407 - val_accuracy: 0.5308\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.0075 - accuracy: 0.6461 - val_loss: 1.3571 - val_accuracy: 0.5279\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.9987 - accuracy: 0.6500 - val_loss: 1.3955 - val_accuracy: 0.5201\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9912 - accuracy: 0.6519 - val_loss: 1.4005 - val_accuracy: 0.5167\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9753 - accuracy: 0.6606 - val_loss: 1.3786 - val_accuracy: 0.5240\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9648 - accuracy: 0.6626 - val_loss: 1.3248 - val_accuracy: 0.5418\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9513 - accuracy: 0.6657 - val_loss: 1.3639 - val_accuracy: 0.5321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9384 - accuracy: 0.6711 - val_loss: 1.3518 - val_accuracy: 0.5324\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9278 - accuracy: 0.6753 - val_loss: 1.4787 - val_accuracy: 0.5020\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.9111 - accuracy: 0.6823 - val_loss: 1.4163 - val_accuracy: 0.5227\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.8984 - accuracy: 0.6845 - val_loss: 1.4457 - val_accuracy: 0.5148\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.8927 - accuracy: 0.6887 - val_loss: 1.3799 - val_accuracy: 0.5321\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.8845 - accuracy: 0.6911 - val_loss: 1.3869 - val_accuracy: 0.5322\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# SGD\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session()\n",
    "    print(\"Experiment with LR = %.6f & OPT = SGD\" %(lr))\n",
    "    model = build_mlp(x_train.shape[1:])\n",
    "    model.summary()\n",
    "    opt = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"], optimizer=opt)\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_test, y_test), shuffle=True)\n",
    "    \n",
    "    # save result...\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    val_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    val_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    name = \"exp-lr-%s-opt-SGD\" %str(lr)\n",
    "    results[name] = {'train-loss': train_loss,\n",
    "                             'valid-loss': val_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000 & OPT = RMSprop\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 18236.6300 - accuracy: 0.0985 - val_loss: 2.3282 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.3085 - accuracy: 0.0983 - val_loss: 2.3063 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3075 - accuracy: 0.1013 - val_loss: 2.3084 - val_accuracy: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3079 - accuracy: 0.0994 - val_loss: 2.3110 - val_accuracy: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3079 - accuracy: 0.0993 - val_loss: 2.3208 - val_accuracy: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3077 - accuracy: 0.0998 - val_loss: 2.3092 - val_accuracy: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3081 - accuracy: 0.0985 - val_loss: 2.3112 - val_accuracy: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.3077 - accuracy: 0.1004 - val_loss: 2.3127 - val_accuracy: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3082 - accuracy: 0.0984 - val_loss: 2.3104 - val_accuracy: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3079 - accuracy: 0.0988 - val_loss: 2.3078 - val_accuracy: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3077 - accuracy: 0.1026 - val_loss: 2.3141 - val_accuracy: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3077 - accuracy: 0.1000 - val_loss: 2.3168 - val_accuracy: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3081 - accuracy: 0.0996 - val_loss: 2.3118 - val_accuracy: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3078 - accuracy: 0.0981 - val_loss: 2.3123 - val_accuracy: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3075 - accuracy: 0.1027 - val_loss: 2.3138 - val_accuracy: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3078 - accuracy: 0.1019 - val_loss: 2.3167 - val_accuracy: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3081 - accuracy: 0.0981 - val_loss: 2.3130 - val_accuracy: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3079 - accuracy: 0.1000 - val_loss: 2.3118 - val_accuracy: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3083 - accuracy: 0.0971 - val_loss: 2.3091 - val_accuracy: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3082 - accuracy: 0.0997 - val_loss: 2.3095 - val_accuracy: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3082 - accuracy: 0.0990 - val_loss: 2.3101 - val_accuracy: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3079 - accuracy: 0.1002 - val_loss: 2.3097 - val_accuracy: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3080 - accuracy: 0.1009 - val_loss: 2.3154 - val_accuracy: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3081 - accuracy: 0.0997 - val_loss: 2.3130 - val_accuracy: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.3077 - accuracy: 0.1004 - val_loss: 2.3162 - val_accuracy: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3081 - accuracy: 0.0984 - val_loss: 2.3099 - val_accuracy: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3079 - accuracy: 0.0975 - val_loss: 2.3156 - val_accuracy: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3077 - accuracy: 0.1000 - val_loss: 2.3188 - val_accuracy: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3073 - accuracy: 0.1025 - val_loss: 2.3090 - val_accuracy: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3075 - accuracy: 0.1032 - val_loss: 2.3059 - val_accuracy: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.3081 - accuracy: 0.0969 - val_loss: 2.3130 - val_accuracy: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3075 - accuracy: 0.1009 - val_loss: 2.3069 - val_accuracy: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3078 - accuracy: 0.0995 - val_loss: 2.3133 - val_accuracy: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3078 - accuracy: 0.0992 - val_loss: 2.3138 - val_accuracy: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3082 - accuracy: 0.0967 - val_loss: 2.3059 - val_accuracy: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3081 - accuracy: 0.1000 - val_loss: 2.3079 - val_accuracy: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3079 - accuracy: 0.0998 - val_loss: 2.3219 - val_accuracy: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3074 - accuracy: 0.0988 - val_loss: 2.3185 - val_accuracy: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3077 - accuracy: 0.1009 - val_loss: 2.3178 - val_accuracy: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3075 - accuracy: 0.1000 - val_loss: 2.3200 - val_accuracy: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3079 - accuracy: 0.0991 - val_loss: 2.3162 - val_accuracy: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.3078 - accuracy: 0.0995 - val_loss: 2.3144 - val_accuracy: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3079 - accuracy: 0.0989 - val_loss: 2.3163 - val_accuracy: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3078 - accuracy: 0.1006 - val_loss: 2.3157 - val_accuracy: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3078 - accuracy: 0.0992 - val_loss: 2.3139 - val_accuracy: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3078 - accuracy: 0.0998 - val_loss: 2.3100 - val_accuracy: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3078 - accuracy: 0.0996 - val_loss: 2.3170 - val_accuracy: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3079 - accuracy: 0.1011 - val_loss: 2.3095 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3078 - accuracy: 0.1026 - val_loss: 2.3105 - val_accuracy: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3076 - accuracy: 0.0993 - val_loss: 2.3151 - val_accuracy: 0.1000\n",
      "Experiment with LR = 0.010000 & OPT = RMSprop\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.7070 - accuracy: 0.1065 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.3329 - accuracy: 0.1055 - val_loss: 2.1779 - val_accuracy: 0.1818\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.1646 - accuracy: 0.1685 - val_loss: 2.0934 - val_accuracy: 0.1725\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.0959 - accuracy: 0.1850 - val_loss: 2.0539 - val_accuracy: 0.1913\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.0526 - accuracy: 0.2129 - val_loss: 2.0276 - val_accuracy: 0.2094\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9920 - accuracy: 0.2512 - val_loss: 2.0768 - val_accuracy: 0.2264\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9568 - accuracy: 0.2686 - val_loss: 1.9022 - val_accuracy: 0.2850\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9357 - accuracy: 0.2736 - val_loss: 1.9837 - val_accuracy: 0.2586\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9212 - accuracy: 0.2801 - val_loss: 1.9803 - val_accuracy: 0.2566\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9073 - accuracy: 0.2882 - val_loss: 2.0481 - val_accuracy: 0.2588\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8979 - accuracy: 0.2940 - val_loss: 2.1005 - val_accuracy: 0.2352\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8870 - accuracy: 0.2977 - val_loss: 2.1496 - val_accuracy: 0.2513\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8740 - accuracy: 0.3004 - val_loss: 2.0285 - val_accuracy: 0.2594\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8626 - accuracy: 0.3062 - val_loss: 1.8727 - val_accuracy: 0.3025\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.8597 - accuracy: 0.3097 - val_loss: 1.9382 - val_accuracy: 0.2787\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8523 - accuracy: 0.3130 - val_loss: 1.8633 - val_accuracy: 0.3126\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8497 - accuracy: 0.3139 - val_loss: 1.8964 - val_accuracy: 0.2944\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8454 - accuracy: 0.3119 - val_loss: 2.1083 - val_accuracy: 0.2494\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.8404 - accuracy: 0.3145 - val_loss: 1.8264 - val_accuracy: 0.3127\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8429 - accuracy: 0.3121 - val_loss: 1.8455 - val_accuracy: 0.3056\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8404 - accuracy: 0.3129 - val_loss: 1.9224 - val_accuracy: 0.3058\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8343 - accuracy: 0.3182 - val_loss: 1.9156 - val_accuracy: 0.2911\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8358 - accuracy: 0.3137 - val_loss: 1.8665 - val_accuracy: 0.2985\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8283 - accuracy: 0.3182 - val_loss: 1.9052 - val_accuracy: 0.2863\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8310 - accuracy: 0.3182 - val_loss: 2.0872 - val_accuracy: 0.2788\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8260 - accuracy: 0.3197 - val_loss: 1.8386 - val_accuracy: 0.3096\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8203 - accuracy: 0.3239 - val_loss: 1.8133 - val_accuracy: 0.3231\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8244 - accuracy: 0.3192 - val_loss: 1.8505 - val_accuracy: 0.3132\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8206 - accuracy: 0.3248 - val_loss: 1.9290 - val_accuracy: 0.3015\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8191 - accuracy: 0.3226 - val_loss: 1.8322 - val_accuracy: 0.3195\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8208 - accuracy: 0.3221 - val_loss: 1.8273 - val_accuracy: 0.3191\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8170 - accuracy: 0.3251 - val_loss: 1.7997 - val_accuracy: 0.3279\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8166 - accuracy: 0.3231 - val_loss: 2.0861 - val_accuracy: 0.2432\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8160 - accuracy: 0.3257 - val_loss: 1.8147 - val_accuracy: 0.3200\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8117 - accuracy: 0.3245 - val_loss: 1.8070 - val_accuracy: 0.3279\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8115 - accuracy: 0.3250 - val_loss: 1.9223 - val_accuracy: 0.2961\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8115 - accuracy: 0.3257 - val_loss: 1.8132 - val_accuracy: 0.3252\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8077 - accuracy: 0.3292 - val_loss: 1.9130 - val_accuracy: 0.2965\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.8107 - accuracy: 0.3271 - val_loss: 1.8465 - val_accuracy: 0.3113\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8048 - accuracy: 0.3297 - val_loss: 1.7975 - val_accuracy: 0.3241\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8040 - accuracy: 0.3320 - val_loss: 1.8533 - val_accuracy: 0.3177\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.8054 - accuracy: 0.3288 - val_loss: 1.8485 - val_accuracy: 0.3055\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8052 - accuracy: 0.3253 - val_loss: 1.8467 - val_accuracy: 0.3046\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8082 - accuracy: 0.3281 - val_loss: 1.8446 - val_accuracy: 0.3146\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8018 - accuracy: 0.3282 - val_loss: 1.8017 - val_accuracy: 0.3251\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8057 - accuracy: 0.3262 - val_loss: 1.7921 - val_accuracy: 0.3322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8023 - accuracy: 0.3290 - val_loss: 1.8385 - val_accuracy: 0.3147\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8037 - accuracy: 0.3294 - val_loss: 2.0303 - val_accuracy: 0.2715\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7996 - accuracy: 0.3296 - val_loss: 1.8023 - val_accuracy: 0.3207\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7987 - accuracy: 0.3275 - val_loss: 1.8614 - val_accuracy: 0.3063\n",
      "Experiment with LR = 0.001000 & OPT = RMSprop\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.2902 - accuracy: 0.2103 - val_loss: 2.0810 - val_accuracy: 0.2405\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8844 - accuracy: 0.3182 - val_loss: 1.8575 - val_accuracy: 0.3253\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7828 - accuracy: 0.3591 - val_loss: 1.7486 - val_accuracy: 0.3679\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7124 - accuracy: 0.3856 - val_loss: 1.7672 - val_accuracy: 0.3788\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6568 - accuracy: 0.4089 - val_loss: 1.6546 - val_accuracy: 0.4152\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6103 - accuracy: 0.4234 - val_loss: 1.8694 - val_accuracy: 0.3575\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.5757 - accuracy: 0.4373 - val_loss: 1.6190 - val_accuracy: 0.4286\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.5362 - accuracy: 0.4527 - val_loss: 1.8298 - val_accuracy: 0.3813\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.5005 - accuracy: 0.4633 - val_loss: 1.8649 - val_accuracy: 0.3761\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.4772 - accuracy: 0.4728 - val_loss: 1.6370 - val_accuracy: 0.4145\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.4479 - accuracy: 0.4826 - val_loss: 1.5701 - val_accuracy: 0.4395\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.4206 - accuracy: 0.4943 - val_loss: 1.6816 - val_accuracy: 0.3970\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3944 - accuracy: 0.5042 - val_loss: 1.4821 - val_accuracy: 0.4686\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3699 - accuracy: 0.5084 - val_loss: 1.5633 - val_accuracy: 0.4400\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3487 - accuracy: 0.5208 - val_loss: 1.5917 - val_accuracy: 0.4488\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3258 - accuracy: 0.5267 - val_loss: 1.5263 - val_accuracy: 0.4613\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3030 - accuracy: 0.5359 - val_loss: 1.7080 - val_accuracy: 0.4158\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2839 - accuracy: 0.5430 - val_loss: 1.6203 - val_accuracy: 0.4358\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2613 - accuracy: 0.5508 - val_loss: 1.5098 - val_accuracy: 0.4703\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2354 - accuracy: 0.5614 - val_loss: 1.4879 - val_accuracy: 0.4930\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2144 - accuracy: 0.5671 - val_loss: 1.5910 - val_accuracy: 0.4430\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.1965 - accuracy: 0.5730 - val_loss: 1.6285 - val_accuracy: 0.4503\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1799 - accuracy: 0.5774 - val_loss: 1.5441 - val_accuracy: 0.4878\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1548 - accuracy: 0.5878 - val_loss: 1.5583 - val_accuracy: 0.4774\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.1333 - accuracy: 0.5971 - val_loss: 1.5486 - val_accuracy: 0.4782\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1189 - accuracy: 0.6012 - val_loss: 1.6444 - val_accuracy: 0.4580\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1023 - accuracy: 0.6051 - val_loss: 1.4793 - val_accuracy: 0.5031\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0785 - accuracy: 0.6141 - val_loss: 1.6114 - val_accuracy: 0.4776\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0636 - accuracy: 0.6209 - val_loss: 1.6494 - val_accuracy: 0.4803\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0421 - accuracy: 0.6298 - val_loss: 1.6197 - val_accuracy: 0.4581\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0307 - accuracy: 0.6311 - val_loss: 1.7950 - val_accuracy: 0.4604\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0103 - accuracy: 0.6381 - val_loss: 1.6275 - val_accuracy: 0.4844\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9996 - accuracy: 0.6414 - val_loss: 1.6633 - val_accuracy: 0.4725\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9789 - accuracy: 0.6485 - val_loss: 1.5916 - val_accuracy: 0.4841\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9623 - accuracy: 0.6586 - val_loss: 1.6455 - val_accuracy: 0.4847\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9515 - accuracy: 0.6613 - val_loss: 1.7680 - val_accuracy: 0.4703\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9365 - accuracy: 0.6665 - val_loss: 1.6089 - val_accuracy: 0.5010\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9146 - accuracy: 0.6713 - val_loss: 1.7941 - val_accuracy: 0.4827\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9070 - accuracy: 0.6748 - val_loss: 1.7029 - val_accuracy: 0.4858\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.8887 - accuracy: 0.6820 - val_loss: 1.7922 - val_accuracy: 0.4742\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.8763 - accuracy: 0.6859 - val_loss: 1.7950 - val_accuracy: 0.4859\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.8631 - accuracy: 0.6901 - val_loss: 1.7722 - val_accuracy: 0.4875\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.8490 - accuracy: 0.6942 - val_loss: 1.8699 - val_accuracy: 0.4674\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.8360 - accuracy: 0.6981 - val_loss: 1.9815 - val_accuracy: 0.4746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.8228 - accuracy: 0.7044 - val_loss: 1.8453 - val_accuracy: 0.4925\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.8121 - accuracy: 0.7099 - val_loss: 1.9538 - val_accuracy: 0.4844\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.7977 - accuracy: 0.7119 - val_loss: 1.8585 - val_accuracy: 0.4897\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.7852 - accuracy: 0.7182 - val_loss: 1.9288 - val_accuracy: 0.4542\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.7774 - accuracy: 0.7214 - val_loss: 1.9963 - val_accuracy: 0.4842\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.7664 - accuracy: 0.7253 - val_loss: 1.9660 - val_accuracy: 0.4620\n"
     ]
    }
   ],
   "source": [
    "# RMSprop\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session()\n",
    "    print(\"Experiment with LR = %.6f & OPT = RMSprop\" %(lr))\n",
    "    model = build_mlp(x_train.shape[1:])\n",
    "    model.summary()\n",
    "    opt = keras.optimizers.RMSprop(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"], optimizer=opt)\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_test, y_test), shuffle=True)\n",
    "    \n",
    "    # save result...\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    val_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    val_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    name = \"exp-lr-%s-opt-RMSprop\" %str(lr)\n",
    "    results[name] = {'train-loss': train_loss,\n",
    "                             'valid-loss': val_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000 & OPT = AdaGrad\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 186.8467 - accuracy: 0.1204 - val_loss: 2.2765 - val_accuracy: 0.1174\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.1951 - accuracy: 0.1704 - val_loss: 2.1664 - val_accuracy: 0.1788\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.1185 - accuracy: 0.2026 - val_loss: 2.1757 - val_accuracy: 0.1807\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.0619 - accuracy: 0.2255 - val_loss: 2.0704 - val_accuracy: 0.2154\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.0149 - accuracy: 0.2430 - val_loss: 1.9915 - val_accuracy: 0.2561\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.9769 - accuracy: 0.2631 - val_loss: 2.1289 - val_accuracy: 0.2008\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9376 - accuracy: 0.2885 - val_loss: 1.9289 - val_accuracy: 0.3045\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8785 - accuracy: 0.3194 - val_loss: 1.8580 - val_accuracy: 0.3303\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8274 - accuracy: 0.3425 - val_loss: 1.9257 - val_accuracy: 0.3063\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7902 - accuracy: 0.3580 - val_loss: 1.8215 - val_accuracy: 0.3431\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7639 - accuracy: 0.3675 - val_loss: 1.8044 - val_accuracy: 0.3465\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7434 - accuracy: 0.3764 - val_loss: 1.7578 - val_accuracy: 0.3796\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7244 - accuracy: 0.3821 - val_loss: 1.8500 - val_accuracy: 0.3331\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7048 - accuracy: 0.3890 - val_loss: 1.8375 - val_accuracy: 0.3460\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6879 - accuracy: 0.3961 - val_loss: 1.8485 - val_accuracy: 0.3338\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6785 - accuracy: 0.3996 - val_loss: 1.7511 - val_accuracy: 0.3777\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6626 - accuracy: 0.4065 - val_loss: 1.7961 - val_accuracy: 0.3556\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6476 - accuracy: 0.4099 - val_loss: 1.6919 - val_accuracy: 0.3884\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6373 - accuracy: 0.4159 - val_loss: 1.7123 - val_accuracy: 0.3939\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6213 - accuracy: 0.4225 - val_loss: 1.6919 - val_accuracy: 0.4004\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6109 - accuracy: 0.4229 - val_loss: 1.7052 - val_accuracy: 0.3938\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5967 - accuracy: 0.4307 - val_loss: 1.6744 - val_accuracy: 0.4045\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5951 - accuracy: 0.4283 - val_loss: 1.6777 - val_accuracy: 0.4134\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5794 - accuracy: 0.4346 - val_loss: 1.6187 - val_accuracy: 0.4255\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5759 - accuracy: 0.4363 - val_loss: 1.6248 - val_accuracy: 0.4203\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5616 - accuracy: 0.4406 - val_loss: 1.6375 - val_accuracy: 0.4207\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5575 - accuracy: 0.4432 - val_loss: 1.6177 - val_accuracy: 0.4213\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5473 - accuracy: 0.4451 - val_loss: 1.6853 - val_accuracy: 0.4005\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5381 - accuracy: 0.4538 - val_loss: 1.6295 - val_accuracy: 0.4196\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5327 - accuracy: 0.4524 - val_loss: 1.6999 - val_accuracy: 0.3965\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5252 - accuracy: 0.4542 - val_loss: 1.5990 - val_accuracy: 0.4306\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5194 - accuracy: 0.4573 - val_loss: 1.5781 - val_accuracy: 0.4367\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5138 - accuracy: 0.4585 - val_loss: 1.6201 - val_accuracy: 0.4209\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5061 - accuracy: 0.4618 - val_loss: 1.6922 - val_accuracy: 0.4109\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5045 - accuracy: 0.4636 - val_loss: 1.6095 - val_accuracy: 0.4281\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4943 - accuracy: 0.4641 - val_loss: 1.6142 - val_accuracy: 0.4272\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4896 - accuracy: 0.4673 - val_loss: 1.5996 - val_accuracy: 0.4359\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4839 - accuracy: 0.4700 - val_loss: 1.5876 - val_accuracy: 0.4411\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4762 - accuracy: 0.4712 - val_loss: 1.6437 - val_accuracy: 0.4193\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4692 - accuracy: 0.4747 - val_loss: 1.5969 - val_accuracy: 0.4309\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4671 - accuracy: 0.4739 - val_loss: 1.5745 - val_accuracy: 0.4421\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4629 - accuracy: 0.4783 - val_loss: 1.8682 - val_accuracy: 0.3614\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4578 - accuracy: 0.4783 - val_loss: 1.6174 - val_accuracy: 0.4325\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4507 - accuracy: 0.4836 - val_loss: 1.6560 - val_accuracy: 0.4199\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4469 - accuracy: 0.4825 - val_loss: 1.5728 - val_accuracy: 0.4451\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4398 - accuracy: 0.4882 - val_loss: 1.5908 - val_accuracy: 0.4428\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4382 - accuracy: 0.4856 - val_loss: 1.5463 - val_accuracy: 0.4525\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4353 - accuracy: 0.4877 - val_loss: 1.5496 - val_accuracy: 0.4564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4308 - accuracy: 0.4891 - val_loss: 1.5499 - val_accuracy: 0.4496\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4217 - accuracy: 0.4917 - val_loss: 1.5466 - val_accuracy: 0.4542\n",
      "Experiment with LR = 0.010000 & OPT = AdaGrad\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.8442 - accuracy: 0.2546 - val_loss: 2.1854 - val_accuracy: 0.2370\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8134 - accuracy: 0.3496 - val_loss: 1.7844 - val_accuracy: 0.3560\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7240 - accuracy: 0.3858 - val_loss: 1.7137 - val_accuracy: 0.3883\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6566 - accuracy: 0.4101 - val_loss: 1.6587 - val_accuracy: 0.4052\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6126 - accuracy: 0.4283 - val_loss: 1.6127 - val_accuracy: 0.4224\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5698 - accuracy: 0.4421 - val_loss: 1.6977 - val_accuracy: 0.3981\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5368 - accuracy: 0.4565 - val_loss: 1.5354 - val_accuracy: 0.4539\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5105 - accuracy: 0.4634 - val_loss: 1.5800 - val_accuracy: 0.4343\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4844 - accuracy: 0.4726 - val_loss: 1.5534 - val_accuracy: 0.4409\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4598 - accuracy: 0.4847 - val_loss: 1.5101 - val_accuracy: 0.4562\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4378 - accuracy: 0.4924 - val_loss: 1.5230 - val_accuracy: 0.4551\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4207 - accuracy: 0.4968 - val_loss: 1.5068 - val_accuracy: 0.4645\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4033 - accuracy: 0.5051 - val_loss: 1.4825 - val_accuracy: 0.4728\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3858 - accuracy: 0.5098 - val_loss: 1.4803 - val_accuracy: 0.4724\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3718 - accuracy: 0.5159 - val_loss: 1.5140 - val_accuracy: 0.4628\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3541 - accuracy: 0.5216 - val_loss: 1.4731 - val_accuracy: 0.4801\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3378 - accuracy: 0.5278 - val_loss: 1.5220 - val_accuracy: 0.4659\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3285 - accuracy: 0.5306 - val_loss: 1.4501 - val_accuracy: 0.4858\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3113 - accuracy: 0.5360 - val_loss: 1.4431 - val_accuracy: 0.4809\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3012 - accuracy: 0.5421 - val_loss: 1.4687 - val_accuracy: 0.4777\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2902 - accuracy: 0.5462 - val_loss: 1.4227 - val_accuracy: 0.4898\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2785 - accuracy: 0.5491 - val_loss: 1.4589 - val_accuracy: 0.4857\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2650 - accuracy: 0.5530 - val_loss: 1.4148 - val_accuracy: 0.4963\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2596 - accuracy: 0.5562 - val_loss: 1.4440 - val_accuracy: 0.4767\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2421 - accuracy: 0.5624 - val_loss: 1.4189 - val_accuracy: 0.4937\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2303 - accuracy: 0.5658 - val_loss: 1.5344 - val_accuracy: 0.4707\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2248 - accuracy: 0.5701 - val_loss: 1.4100 - val_accuracy: 0.5059\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2105 - accuracy: 0.5743 - val_loss: 1.4148 - val_accuracy: 0.5048\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2046 - accuracy: 0.5768 - val_loss: 1.3887 - val_accuracy: 0.5104\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1916 - accuracy: 0.5798 - val_loss: 1.4695 - val_accuracy: 0.4862\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1823 - accuracy: 0.5840 - val_loss: 1.4750 - val_accuracy: 0.4791\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1777 - accuracy: 0.5861 - val_loss: 1.4130 - val_accuracy: 0.5097\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1648 - accuracy: 0.5887 - val_loss: 1.3903 - val_accuracy: 0.5092\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1578 - accuracy: 0.5930 - val_loss: 1.4254 - val_accuracy: 0.5109\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1474 - accuracy: 0.5972 - val_loss: 1.4011 - val_accuracy: 0.5130\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1411 - accuracy: 0.5995 - val_loss: 1.3770 - val_accuracy: 0.5183\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1329 - accuracy: 0.6006 - val_loss: 1.3791 - val_accuracy: 0.5177\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1226 - accuracy: 0.6065 - val_loss: 1.3573 - val_accuracy: 0.5229\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1142 - accuracy: 0.6089 - val_loss: 1.3760 - val_accuracy: 0.5201\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1091 - accuracy: 0.6108 - val_loss: 1.3872 - val_accuracy: 0.5156\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0972 - accuracy: 0.6147 - val_loss: 1.4226 - val_accuracy: 0.5083\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0954 - accuracy: 0.6157 - val_loss: 1.3744 - val_accuracy: 0.5184\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0822 - accuracy: 0.6197 - val_loss: 1.5068 - val_accuracy: 0.4905\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0777 - accuracy: 0.6219 - val_loss: 1.4122 - val_accuracy: 0.5133\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0682 - accuracy: 0.6273 - val_loss: 1.3644 - val_accuracy: 0.5249\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0645 - accuracy: 0.6284 - val_loss: 1.3485 - val_accuracy: 0.5305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0555 - accuracy: 0.6293 - val_loss: 1.3867 - val_accuracy: 0.5209\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0488 - accuracy: 0.6336 - val_loss: 1.4043 - val_accuracy: 0.5213\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0425 - accuracy: 0.6358 - val_loss: 1.3710 - val_accuracy: 0.5258\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0350 - accuracy: 0.6390 - val_loss: 1.4061 - val_accuracy: 0.5185\n",
      "Experiment with LR = 0.001000 & OPT = AdaGrad\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9899 - accuracy: 0.2843 - val_loss: 1.9161 - val_accuracy: 0.2914\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8003 - accuracy: 0.3634 - val_loss: 1.7819 - val_accuracy: 0.3509\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7276 - accuracy: 0.3908 - val_loss: 1.7386 - val_accuracy: 0.3772\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6776 - accuracy: 0.4086 - val_loss: 1.6852 - val_accuracy: 0.3987\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6417 - accuracy: 0.4214 - val_loss: 1.6475 - val_accuracy: 0.4176\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6108 - accuracy: 0.4355 - val_loss: 1.6322 - val_accuracy: 0.4238\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5867 - accuracy: 0.4420 - val_loss: 1.6062 - val_accuracy: 0.4286\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5666 - accuracy: 0.4520 - val_loss: 1.6274 - val_accuracy: 0.4227\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5489 - accuracy: 0.4574 - val_loss: 1.5668 - val_accuracy: 0.4519\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5315 - accuracy: 0.4626 - val_loss: 1.6160 - val_accuracy: 0.4267\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5170 - accuracy: 0.4694 - val_loss: 1.5575 - val_accuracy: 0.4464\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5028 - accuracy: 0.4754 - val_loss: 1.5355 - val_accuracy: 0.4588\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4893 - accuracy: 0.4794 - val_loss: 1.5219 - val_accuracy: 0.4606\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4770 - accuracy: 0.4836 - val_loss: 1.5186 - val_accuracy: 0.4641\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4662 - accuracy: 0.4886 - val_loss: 1.5114 - val_accuracy: 0.4725\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4564 - accuracy: 0.4914 - val_loss: 1.4905 - val_accuracy: 0.4755\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4444 - accuracy: 0.4954 - val_loss: 1.5064 - val_accuracy: 0.4689\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4351 - accuracy: 0.4982 - val_loss: 1.4958 - val_accuracy: 0.4710\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4264 - accuracy: 0.5031 - val_loss: 1.4887 - val_accuracy: 0.4748\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4171 - accuracy: 0.5046 - val_loss: 1.4889 - val_accuracy: 0.4700\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4091 - accuracy: 0.5074 - val_loss: 1.4934 - val_accuracy: 0.4655\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.4003 - accuracy: 0.5120 - val_loss: 1.4653 - val_accuracy: 0.4820\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3919 - accuracy: 0.5137 - val_loss: 1.4604 - val_accuracy: 0.4795\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3853 - accuracy: 0.5169 - val_loss: 1.4419 - val_accuracy: 0.4874\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3767 - accuracy: 0.5207 - val_loss: 1.4641 - val_accuracy: 0.4845\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3702 - accuracy: 0.5218 - val_loss: 1.4410 - val_accuracy: 0.4858\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3640 - accuracy: 0.5262 - val_loss: 1.4682 - val_accuracy: 0.4715\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3562 - accuracy: 0.5274 - val_loss: 1.4381 - val_accuracy: 0.4893\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3508 - accuracy: 0.5282 - val_loss: 1.4402 - val_accuracy: 0.4924\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3452 - accuracy: 0.5325 - val_loss: 1.4333 - val_accuracy: 0.4857\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3398 - accuracy: 0.5331 - val_loss: 1.4123 - val_accuracy: 0.4961\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3330 - accuracy: 0.5377 - val_loss: 1.4426 - val_accuracy: 0.4846\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3272 - accuracy: 0.5382 - val_loss: 1.4721 - val_accuracy: 0.4843\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3216 - accuracy: 0.5394 - val_loss: 1.4168 - val_accuracy: 0.4970\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3152 - accuracy: 0.5442 - val_loss: 1.3986 - val_accuracy: 0.5055\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3099 - accuracy: 0.5446 - val_loss: 1.3922 - val_accuracy: 0.5076\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3054 - accuracy: 0.5472 - val_loss: 1.4113 - val_accuracy: 0.4913\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2998 - accuracy: 0.5486 - val_loss: 1.4016 - val_accuracy: 0.5049\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2951 - accuracy: 0.5498 - val_loss: 1.4104 - val_accuracy: 0.4946\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2905 - accuracy: 0.5521 - val_loss: 1.3905 - val_accuracy: 0.5073\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2853 - accuracy: 0.5535 - val_loss: 1.3887 - val_accuracy: 0.5096\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2804 - accuracy: 0.5556 - val_loss: 1.3791 - val_accuracy: 0.5108\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2757 - accuracy: 0.5582 - val_loss: 1.3775 - val_accuracy: 0.5125\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2708 - accuracy: 0.5588 - val_loss: 1.4048 - val_accuracy: 0.5003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2671 - accuracy: 0.5599 - val_loss: 1.4014 - val_accuracy: 0.5029\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2627 - accuracy: 0.5614 - val_loss: 1.3822 - val_accuracy: 0.5056\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2577 - accuracy: 0.5644 - val_loss: 1.3969 - val_accuracy: 0.5056\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2546 - accuracy: 0.5656 - val_loss: 1.3690 - val_accuracy: 0.5162\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2493 - accuracy: 0.5667 - val_loss: 1.3952 - val_accuracy: 0.5075\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2458 - accuracy: 0.5690 - val_loss: 1.3951 - val_accuracy: 0.5076\n"
     ]
    }
   ],
   "source": [
    "# AdaGrad\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session()\n",
    "    print(\"Experiment with LR = %.6f & OPT = AdaGrad\" %(lr))\n",
    "    model = build_mlp(x_train.shape[1:])\n",
    "    model.summary()\n",
    "    opt = keras.optimizers.Adagrad(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"], optimizer=opt)\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_test, y_test), shuffle=True)\n",
    "    \n",
    "    # save result...\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    val_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    val_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    name = \"exp-lr-%s-opt-Adagrad\" %str(lr)\n",
    "    results[name] = {'train-loss': train_loss,\n",
    "                             'valid-loss': val_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000 & OPT = AdaGrad\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 353.4189 - accuracy: 0.0993 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3048 - accuracy: 0.1021 - val_loss: 2.3135 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3042 - accuracy: 0.1001 - val_loss: 2.3147 - val_accuracy: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3047 - accuracy: 0.1005 - val_loss: 2.3146 - val_accuracy: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3045 - accuracy: 0.1017 - val_loss: 2.3153 - val_accuracy: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3053 - accuracy: 0.0973 - val_loss: 2.3187 - val_accuracy: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3059 - accuracy: 0.0996 - val_loss: 2.3160 - val_accuracy: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 62us/step - loss: 2.3058 - accuracy: 0.1002 - val_loss: 2.3149 - val_accuracy: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3055 - accuracy: 0.0982 - val_loss: 2.3189 - val_accuracy: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3071 - accuracy: 0.0981 - val_loss: 2.3175 - val_accuracy: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3061 - accuracy: 0.0969 - val_loss: 2.3149 - val_accuracy: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3056 - accuracy: 0.0988 - val_loss: 2.3167 - val_accuracy: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3061 - accuracy: 0.1016 - val_loss: 2.3139 - val_accuracy: 0.0999\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3062 - accuracy: 0.0999 - val_loss: 2.3165 - val_accuracy: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3065 - accuracy: 0.1012 - val_loss: 2.3173 - val_accuracy: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3064 - accuracy: 0.1023 - val_loss: 2.3203 - val_accuracy: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3072 - accuracy: 0.0997 - val_loss: 2.3169 - val_accuracy: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3068 - accuracy: 0.1005 - val_loss: 2.3157 - val_accuracy: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3062 - accuracy: 0.1010 - val_loss: 2.3225 - val_accuracy: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3070 - accuracy: 0.0997 - val_loss: 2.3182 - val_accuracy: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3067 - accuracy: 0.1009 - val_loss: 2.3155 - val_accuracy: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3070 - accuracy: 0.1001 - val_loss: 2.3167 - val_accuracy: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3065 - accuracy: 0.1005 - val_loss: 2.3169 - val_accuracy: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3070 - accuracy: 0.0991 - val_loss: 2.3166 - val_accuracy: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3067 - accuracy: 0.1000 - val_loss: 2.3150 - val_accuracy: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3069 - accuracy: 0.0995 - val_loss: 2.3149 - val_accuracy: 0.0999\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3059 - accuracy: 0.0985 - val_loss: 2.3163 - val_accuracy: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3075 - accuracy: 0.0997 - val_loss: 2.3170 - val_accuracy: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3065 - accuracy: 0.0988 - val_loss: 2.3195 - val_accuracy: 0.0999\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3070 - accuracy: 0.0990 - val_loss: 2.3187 - val_accuracy: 0.0999\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3075 - accuracy: 0.0998 - val_loss: 2.3157 - val_accuracy: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3067 - accuracy: 0.0996 - val_loss: 2.3142 - val_accuracy: 0.0999\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3068 - accuracy: 0.0997 - val_loss: 2.3166 - val_accuracy: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3068 - accuracy: 0.1006 - val_loss: 2.3154 - val_accuracy: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3068 - accuracy: 0.0994 - val_loss: 2.3169 - val_accuracy: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3076 - accuracy: 0.0997 - val_loss: 2.3151 - val_accuracy: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3082 - accuracy: 0.1011 - val_loss: 2.3171 - val_accuracy: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3069 - accuracy: 0.0978 - val_loss: 2.3195 - val_accuracy: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3071 - accuracy: 0.0995 - val_loss: 2.3174 - val_accuracy: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3064 - accuracy: 0.1002 - val_loss: 2.3181 - val_accuracy: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3073 - accuracy: 0.1008 - val_loss: 2.3174 - val_accuracy: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3067 - accuracy: 0.0994 - val_loss: 2.3144 - val_accuracy: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3066 - accuracy: 0.0969 - val_loss: 2.3153 - val_accuracy: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3074 - accuracy: 0.0986 - val_loss: 2.3147 - val_accuracy: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3066 - accuracy: 0.1000 - val_loss: 2.3188 - val_accuracy: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3067 - accuracy: 0.1005 - val_loss: 2.3184 - val_accuracy: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3069 - accuracy: 0.1005 - val_loss: 2.3165 - val_accuracy: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3069 - accuracy: 0.1021 - val_loss: 2.3175 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.3062 - accuracy: 0.0996 - val_loss: 2.3184 - val_accuracy: 0.0999\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3067 - accuracy: 0.1015 - val_loss: 2.3148 - val_accuracy: 0.0999\n",
      "Experiment with LR = 0.010000 & OPT = AdaGrad\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 3.2281 - accuracy: 0.2335 - val_loss: 1.8784 - val_accuracy: 0.3122\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.8241 - accuracy: 0.3367 - val_loss: 1.7817 - val_accuracy: 0.3555\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7667 - accuracy: 0.3608 - val_loss: 1.7493 - val_accuracy: 0.3595\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7187 - accuracy: 0.3786 - val_loss: 1.7026 - val_accuracy: 0.3789\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6837 - accuracy: 0.3922 - val_loss: 1.6644 - val_accuracy: 0.3996\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6558 - accuracy: 0.4051 - val_loss: 1.6492 - val_accuracy: 0.4024\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6437 - accuracy: 0.4064 - val_loss: 1.6321 - val_accuracy: 0.4166\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6213 - accuracy: 0.4148 - val_loss: 1.6679 - val_accuracy: 0.3977\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6322 - accuracy: 0.4123 - val_loss: 1.6787 - val_accuracy: 0.3923\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6102 - accuracy: 0.4194 - val_loss: 1.6449 - val_accuracy: 0.4032\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5925 - accuracy: 0.4257 - val_loss: 1.6459 - val_accuracy: 0.4095\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6000 - accuracy: 0.4255 - val_loss: 1.5767 - val_accuracy: 0.4381\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5842 - accuracy: 0.4273 - val_loss: 1.5754 - val_accuracy: 0.4331\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5791 - accuracy: 0.4280 - val_loss: 1.6124 - val_accuracy: 0.4253\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5818 - accuracy: 0.4272 - val_loss: 1.6488 - val_accuracy: 0.4112\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5709 - accuracy: 0.4328 - val_loss: 1.6523 - val_accuracy: 0.4087\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5724 - accuracy: 0.4319 - val_loss: 1.6302 - val_accuracy: 0.4165\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5675 - accuracy: 0.4353 - val_loss: 1.5931 - val_accuracy: 0.4293\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5689 - accuracy: 0.4351 - val_loss: 1.6234 - val_accuracy: 0.4173\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5688 - accuracy: 0.4332 - val_loss: 1.5893 - val_accuracy: 0.4376\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5558 - accuracy: 0.4377 - val_loss: 1.5971 - val_accuracy: 0.4312\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5593 - accuracy: 0.4377 - val_loss: 1.6167 - val_accuracy: 0.4176\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5576 - accuracy: 0.4354 - val_loss: 1.5848 - val_accuracy: 0.4298\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5583 - accuracy: 0.4380 - val_loss: 1.6635 - val_accuracy: 0.4026\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5607 - accuracy: 0.4357 - val_loss: 1.5867 - val_accuracy: 0.4329\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5439 - accuracy: 0.4394 - val_loss: 1.5662 - val_accuracy: 0.4321\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5529 - accuracy: 0.4351 - val_loss: 1.6243 - val_accuracy: 0.4109\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5493 - accuracy: 0.4422 - val_loss: 1.5719 - val_accuracy: 0.4297\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5476 - accuracy: 0.4428 - val_loss: 1.6125 - val_accuracy: 0.4266\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5548 - accuracy: 0.4380 - val_loss: 1.6205 - val_accuracy: 0.4195\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5565 - accuracy: 0.4419 - val_loss: 1.6614 - val_accuracy: 0.4027\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5544 - accuracy: 0.4342 - val_loss: 1.6404 - val_accuracy: 0.4103\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5485 - accuracy: 0.4419 - val_loss: 1.6354 - val_accuracy: 0.4153\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5431 - accuracy: 0.4425 - val_loss: 1.7038 - val_accuracy: 0.4023\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5497 - accuracy: 0.4411 - val_loss: 1.5796 - val_accuracy: 0.4337\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5478 - accuracy: 0.4413 - val_loss: 1.6896 - val_accuracy: 0.3943\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5508 - accuracy: 0.4410 - val_loss: 1.6542 - val_accuracy: 0.4146\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5531 - accuracy: 0.4414 - val_loss: 1.6328 - val_accuracy: 0.4239\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5394 - accuracy: 0.4436 - val_loss: 1.6133 - val_accuracy: 0.4182\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5410 - accuracy: 0.4449 - val_loss: 1.6275 - val_accuracy: 0.4213\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5408 - accuracy: 0.4422 - val_loss: 1.6164 - val_accuracy: 0.4135\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5304 - accuracy: 0.4482 - val_loss: 1.6639 - val_accuracy: 0.4141\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5536 - accuracy: 0.4401 - val_loss: 1.5903 - val_accuracy: 0.4315\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5353 - accuracy: 0.4463 - val_loss: 1.5902 - val_accuracy: 0.4290\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5414 - accuracy: 0.4436 - val_loss: 1.6304 - val_accuracy: 0.4163\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5346 - accuracy: 0.4482 - val_loss: 1.6526 - val_accuracy: 0.4123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5329 - accuracy: 0.4487 - val_loss: 1.6228 - val_accuracy: 0.4264\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5328 - accuracy: 0.4472 - val_loss: 1.5984 - val_accuracy: 0.4299\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5394 - accuracy: 0.4459 - val_loss: 1.6043 - val_accuracy: 0.4282\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5425 - accuracy: 0.4464 - val_loss: 1.7250 - val_accuracy: 0.3940\n",
      "Experiment with LR = 0.001000 & OPT = AdaGrad\n",
      "512\n",
      "256\n",
      "128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.9164 - accuracy: 0.3102 - val_loss: 1.7220 - val_accuracy: 0.3801\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6890 - accuracy: 0.3947 - val_loss: 1.6077 - val_accuracy: 0.4275\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6015 - accuracy: 0.4270 - val_loss: 1.5766 - val_accuracy: 0.4378\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5408 - accuracy: 0.4503 - val_loss: 1.5552 - val_accuracy: 0.4461\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5045 - accuracy: 0.4641 - val_loss: 1.4971 - val_accuracy: 0.4666\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4556 - accuracy: 0.4816 - val_loss: 1.4792 - val_accuracy: 0.4698\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4250 - accuracy: 0.4912 - val_loss: 1.4659 - val_accuracy: 0.4749\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3976 - accuracy: 0.5018 - val_loss: 1.4661 - val_accuracy: 0.4863\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3677 - accuracy: 0.5110 - val_loss: 1.4574 - val_accuracy: 0.4877\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3435 - accuracy: 0.5208 - val_loss: 1.4361 - val_accuracy: 0.4942\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3089 - accuracy: 0.5352 - val_loss: 1.3986 - val_accuracy: 0.4984\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.2896 - accuracy: 0.5400 - val_loss: 1.3801 - val_accuracy: 0.5095\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.2670 - accuracy: 0.5470 - val_loss: 1.3965 - val_accuracy: 0.5068\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.2540 - accuracy: 0.5530 - val_loss: 1.3650 - val_accuracy: 0.5192\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2281 - accuracy: 0.5623 - val_loss: 1.3908 - val_accuracy: 0.5091\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.2128 - accuracy: 0.5671 - val_loss: 1.3721 - val_accuracy: 0.5188\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1822 - accuracy: 0.5778 - val_loss: 1.3572 - val_accuracy: 0.5275\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1640 - accuracy: 0.5851 - val_loss: 1.3772 - val_accuracy: 0.5196\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1407 - accuracy: 0.5939 - val_loss: 1.3729 - val_accuracy: 0.5164\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1180 - accuracy: 0.6026 - val_loss: 1.3709 - val_accuracy: 0.5252\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0987 - accuracy: 0.6070 - val_loss: 1.4179 - val_accuracy: 0.5124\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0677 - accuracy: 0.6187 - val_loss: 1.4036 - val_accuracy: 0.5124\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0615 - accuracy: 0.6223 - val_loss: 1.3848 - val_accuracy: 0.5186\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0367 - accuracy: 0.6310 - val_loss: 1.3722 - val_accuracy: 0.5332\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0176 - accuracy: 0.6372 - val_loss: 1.4086 - val_accuracy: 0.5196\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.9971 - accuracy: 0.6440 - val_loss: 1.4100 - val_accuracy: 0.5261\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.9883 - accuracy: 0.6464 - val_loss: 1.4140 - val_accuracy: 0.5171\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.9603 - accuracy: 0.6579 - val_loss: 1.4344 - val_accuracy: 0.5251\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.9483 - accuracy: 0.6592 - val_loss: 1.4190 - val_accuracy: 0.5244\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.9300 - accuracy: 0.6684 - val_loss: 1.4509 - val_accuracy: 0.5203\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.9004 - accuracy: 0.6816 - val_loss: 1.4549 - val_accuracy: 0.5247\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.8873 - accuracy: 0.6833 - val_loss: 1.5112 - val_accuracy: 0.5172\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.8673 - accuracy: 0.6889 - val_loss: 1.5216 - val_accuracy: 0.5103\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.8571 - accuracy: 0.6929 - val_loss: 1.4892 - val_accuracy: 0.5262\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.8366 - accuracy: 0.7026 - val_loss: 1.5259 - val_accuracy: 0.5218\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.8118 - accuracy: 0.7102 - val_loss: 1.5282 - val_accuracy: 0.5239\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.8013 - accuracy: 0.7144 - val_loss: 1.5987 - val_accuracy: 0.5158\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.7880 - accuracy: 0.7172 - val_loss: 1.5727 - val_accuracy: 0.5219\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.7660 - accuracy: 0.7273 - val_loss: 1.5524 - val_accuracy: 0.5137\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.7641 - accuracy: 0.7289 - val_loss: 1.6043 - val_accuracy: 0.5251\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.7422 - accuracy: 0.7352 - val_loss: 1.6066 - val_accuracy: 0.5255\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.7146 - accuracy: 0.7452 - val_loss: 1.6111 - val_accuracy: 0.5235\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.7086 - accuracy: 0.7463 - val_loss: 1.6322 - val_accuracy: 0.5175\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.6960 - accuracy: 0.7517 - val_loss: 1.6701 - val_accuracy: 0.5165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.6935 - accuracy: 0.7535 - val_loss: 1.7227 - val_accuracy: 0.5121\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.6637 - accuracy: 0.7634 - val_loss: 1.8068 - val_accuracy: 0.5125\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.6427 - accuracy: 0.7704 - val_loss: 1.7828 - val_accuracy: 0.5136\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.6416 - accuracy: 0.7699 - val_loss: 1.7700 - val_accuracy: 0.5156\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.6254 - accuracy: 0.7767 - val_loss: 1.8224 - val_accuracy: 0.5216\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.6204 - accuracy: 0.7777 - val_loss: 1.8345 - val_accuracy: 0.5196\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session()\n",
    "    print(\"Experiment with LR = %.6f & OPT = AdaGrad\" %(lr))\n",
    "    model = build_mlp(x_train.shape[1:])\n",
    "    model.summary()\n",
    "    opt = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"], optimizer=opt)\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_test, y_test), shuffle=True)\n",
    "    \n",
    "    # save result...\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    val_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    val_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    name = \"exp-lr-%s-opt-Adam\" %str(lr)\n",
    "    results[name] = {'train-loss': train_loss,\n",
    "                             'valid-loss': val_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp-lr-0.1-opt-SGD': {'train-loss': [2.0548087087249756,\n",
       "   1.7754415576171876,\n",
       "   1.74776319732666,\n",
       "   1.7046057897567748,\n",
       "   1.6694256888580323,\n",
       "   1.6488727339935303,\n",
       "   1.6320911679840089,\n",
       "   1.6194213220977782,\n",
       "   1.6212656949615478,\n",
       "   1.5988646196746825,\n",
       "   1.5950844795989991,\n",
       "   1.58500548248291,\n",
       "   1.5912244568252563,\n",
       "   1.5793980801010132,\n",
       "   1.5663886252212524,\n",
       "   1.562698892211914,\n",
       "   1.5500181798171997,\n",
       "   1.541436072769165,\n",
       "   1.5336369478988647,\n",
       "   1.5341217770385742,\n",
       "   1.5345884090423585,\n",
       "   1.5261653203582763,\n",
       "   1.5185251537704467,\n",
       "   1.5242558013916017,\n",
       "   1.5164338250350953,\n",
       "   1.5115650183868408,\n",
       "   1.5048860900115968,\n",
       "   1.4964520516204833,\n",
       "   1.500701470413208,\n",
       "   1.4909519234466553,\n",
       "   1.4794026222991943,\n",
       "   1.4854986529541017,\n",
       "   1.4841299878692626,\n",
       "   1.469326046218872,\n",
       "   1.4698661129379273,\n",
       "   1.4621266816329956,\n",
       "   1.4721758574676513,\n",
       "   1.469955594215393,\n",
       "   1.4498886008453369,\n",
       "   1.4458223410034179,\n",
       "   1.4503244808197022,\n",
       "   1.4507812717437745,\n",
       "   1.4486603507614135,\n",
       "   1.4293676294708253,\n",
       "   1.4336390326309205,\n",
       "   1.4328075241851808,\n",
       "   1.4310474201202392,\n",
       "   1.4230039870452882,\n",
       "   1.4144200217437743,\n",
       "   1.4218271479034423],\n",
       "  'valid-loss': [1.8013331447601317,\n",
       "   1.838697430419922,\n",
       "   1.6927072792053222,\n",
       "   1.829378942489624,\n",
       "   1.706224140739441,\n",
       "   1.6634262884140014,\n",
       "   1.666957689857483,\n",
       "   1.6373323989868165,\n",
       "   1.629602661895752,\n",
       "   1.8427009950637818,\n",
       "   1.6666556743621825,\n",
       "   1.6853200017929078,\n",
       "   1.7021581645965576,\n",
       "   1.6967540964126586,\n",
       "   1.6611662267684937,\n",
       "   1.7189074111938476,\n",
       "   1.65223160572052,\n",
       "   1.7211581174850463,\n",
       "   1.7046273481369019,\n",
       "   1.6878823642730714,\n",
       "   1.6647614553451537,\n",
       "   1.7090728399276733,\n",
       "   1.7150026363372803,\n",
       "   1.7150749374389649,\n",
       "   1.6228655281066895,\n",
       "   1.6900085126876832,\n",
       "   1.6155079078674317,\n",
       "   1.63715910987854,\n",
       "   1.6281207359313965,\n",
       "   1.6555379152297973,\n",
       "   1.6505962965011596,\n",
       "   1.6760324798583985,\n",
       "   1.6115905334472655,\n",
       "   1.643640421104431,\n",
       "   1.5864128498077392,\n",
       "   1.6392365768432617,\n",
       "   1.6529735542297364,\n",
       "   1.7156093811035156,\n",
       "   1.6068771877288819,\n",
       "   1.677756344604492,\n",
       "   1.7459035659790039,\n",
       "   1.6302629711151122,\n",
       "   1.6778683809280395,\n",
       "   1.6760910690307618,\n",
       "   1.6613606418609619,\n",
       "   1.6459450983047486,\n",
       "   1.5866889442443848,\n",
       "   1.669620867538452,\n",
       "   1.6791460809707641,\n",
       "   1.7199793277740478],\n",
       "  'train-acc': [0.23968,\n",
       "   0.3604,\n",
       "   0.37076,\n",
       "   0.391,\n",
       "   0.40252,\n",
       "   0.4097,\n",
       "   0.41856,\n",
       "   0.4222,\n",
       "   0.42036,\n",
       "   0.43114,\n",
       "   0.4306,\n",
       "   0.43384,\n",
       "   0.43224,\n",
       "   0.44004,\n",
       "   0.44362,\n",
       "   0.44434,\n",
       "   0.44858,\n",
       "   0.45424,\n",
       "   0.45556,\n",
       "   0.45448,\n",
       "   0.45584,\n",
       "   0.45686,\n",
       "   0.46278,\n",
       "   0.46086,\n",
       "   0.46434,\n",
       "   0.46486,\n",
       "   0.46842,\n",
       "   0.47248,\n",
       "   0.46784,\n",
       "   0.47372,\n",
       "   0.47466,\n",
       "   0.47726,\n",
       "   0.48072,\n",
       "   0.48414,\n",
       "   0.48194,\n",
       "   0.48606,\n",
       "   0.48256,\n",
       "   0.48352,\n",
       "   0.48946,\n",
       "   0.49274,\n",
       "   0.4909,\n",
       "   0.48934,\n",
       "   0.48882,\n",
       "   0.50046,\n",
       "   0.49632,\n",
       "   0.49734,\n",
       "   0.50052,\n",
       "   0.50272,\n",
       "   0.50292,\n",
       "   0.50192],\n",
       "  'valid-acc': [0.3483999967575073,\n",
       "   0.314300000667572,\n",
       "   0.3921000063419342,\n",
       "   0.3668999969959259,\n",
       "   0.40049999952316284,\n",
       "   0.4074000120162964,\n",
       "   0.3953999876976013,\n",
       "   0.40849998593330383,\n",
       "   0.4169999957084656,\n",
       "   0.36390000581741333,\n",
       "   0.41260001063346863,\n",
       "   0.3944000005722046,\n",
       "   0.40149998664855957,\n",
       "   0.40790000557899475,\n",
       "   0.41449999809265137,\n",
       "   0.4115999937057495,\n",
       "   0.41350001096725464,\n",
       "   0.39149999618530273,\n",
       "   0.39070001244544983,\n",
       "   0.4018999934196472,\n",
       "   0.42969998717308044,\n",
       "   0.4153999984264374,\n",
       "   0.40400001406669617,\n",
       "   0.39719998836517334,\n",
       "   0.42410001158714294,\n",
       "   0.4180999994277954,\n",
       "   0.4284999966621399,\n",
       "   0.43050000071525574,\n",
       "   0.4307999908924103,\n",
       "   0.40950000286102295,\n",
       "   0.4194999933242798,\n",
       "   0.4212999939918518,\n",
       "   0.44830000400543213,\n",
       "   0.4262000024318695,\n",
       "   0.4462999999523163,\n",
       "   0.4399999976158142,\n",
       "   0.42410001158714294,\n",
       "   0.41499999165534973,\n",
       "   0.43799999356269836,\n",
       "   0.42559999227523804,\n",
       "   0.41190001368522644,\n",
       "   0.4327000081539154,\n",
       "   0.44609999656677246,\n",
       "   0.43689998984336853,\n",
       "   0.43470001220703125,\n",
       "   0.4399999976158142,\n",
       "   0.45339998602867126,\n",
       "   0.4253000020980835,\n",
       "   0.43209999799728394,\n",
       "   0.4242999851703644]},\n",
       " 'exp-lr-0.01-opt-SGD': {'train-loss': [1.8212450115203858,\n",
       "   1.5981576473236083,\n",
       "   1.5016091054534912,\n",
       "   1.4435489363861085,\n",
       "   1.3936732150650024,\n",
       "   1.3618957624053956,\n",
       "   1.3228520547103881,\n",
       "   1.2871040590667724,\n",
       "   1.2536036476898194,\n",
       "   1.2280131015014648,\n",
       "   1.1958852648925782,\n",
       "   1.1671081916427613,\n",
       "   1.137338713684082,\n",
       "   1.1150259547424317,\n",
       "   1.0899789630889893,\n",
       "   1.0657230160522462,\n",
       "   1.0475190158843994,\n",
       "   1.011197910938263,\n",
       "   0.9935610719299316,\n",
       "   0.9640485513305664,\n",
       "   0.941827013168335,\n",
       "   0.9230938273239135,\n",
       "   0.8862688528060914,\n",
       "   0.8692939788627625,\n",
       "   0.8462186981582641,\n",
       "   0.8155469177055359,\n",
       "   0.7943113236808776,\n",
       "   0.7699750428009033,\n",
       "   0.7477497874069214,\n",
       "   0.7280012675476074,\n",
       "   0.7027322790908813,\n",
       "   0.6821236619758606,\n",
       "   0.6611075071525574,\n",
       "   0.6283388059616088,\n",
       "   0.609145025100708,\n",
       "   0.595986812171936,\n",
       "   0.5689607464790344,\n",
       "   0.5643125980949402,\n",
       "   0.5391179649734497,\n",
       "   0.52183718501091,\n",
       "   0.49441399671554564,\n",
       "   0.48441218601226804,\n",
       "   0.47018743103027344,\n",
       "   0.4429443305778503,\n",
       "   0.43024513265609743,\n",
       "   0.42424342089653017,\n",
       "   0.39142338128089904,\n",
       "   0.389829330368042,\n",
       "   0.3796419540023804,\n",
       "   0.373354024105072],\n",
       "  'valid-loss': [1.7861783155441284,\n",
       "   1.5589715049743653,\n",
       "   1.6384548488616943,\n",
       "   1.5667924140930176,\n",
       "   1.4294084156036377,\n",
       "   1.4031679279327394,\n",
       "   1.3898699867248536,\n",
       "   1.3836537797927857,\n",
       "   1.4596473978042603,\n",
       "   1.3367840705871583,\n",
       "   1.3370287506103515,\n",
       "   1.3515757205963135,\n",
       "   1.3769251161575318,\n",
       "   1.3418173168182372,\n",
       "   1.384486340713501,\n",
       "   1.3915023666381836,\n",
       "   1.4055972942352295,\n",
       "   1.4239957370758056,\n",
       "   1.3437218706130982,\n",
       "   1.4228372924804686,\n",
       "   1.5022776245117186,\n",
       "   1.38129485206604,\n",
       "   1.5034451641082764,\n",
       "   1.4541868968963623,\n",
       "   1.4626661293029786,\n",
       "   1.4771899457931519,\n",
       "   1.4974070571899414,\n",
       "   1.5393461582183838,\n",
       "   1.626704767036438,\n",
       "   1.5496013898849488,\n",
       "   1.522909808921814,\n",
       "   1.5795624977111817,\n",
       "   1.5892992561340331,\n",
       "   1.6610053173065185,\n",
       "   1.6916643436431884,\n",
       "   1.7517152875900268,\n",
       "   1.7508455307006836,\n",
       "   1.863213973426819,\n",
       "   1.8398447391510009,\n",
       "   1.8524609142303468,\n",
       "   1.8967518287658691,\n",
       "   1.9612458518981934,\n",
       "   1.9511238569259644,\n",
       "   2.073269982910156,\n",
       "   2.090593105316162,\n",
       "   2.1690252990722656,\n",
       "   2.2097784286499023,\n",
       "   2.2652907487869265,\n",
       "   2.240495199584961,\n",
       "   2.3070699092864992],\n",
       "  'train-acc': [0.34876,\n",
       "   0.43242,\n",
       "   0.465,\n",
       "   0.4856,\n",
       "   0.5025,\n",
       "   0.51788,\n",
       "   0.53006,\n",
       "   0.54226,\n",
       "   0.55576,\n",
       "   0.56378,\n",
       "   0.57682,\n",
       "   0.58414,\n",
       "   0.59558,\n",
       "   0.60238,\n",
       "   0.6138,\n",
       "   0.6194,\n",
       "   0.6258,\n",
       "   0.63974,\n",
       "   0.6454,\n",
       "   0.65518,\n",
       "   0.66374,\n",
       "   0.6707,\n",
       "   0.68416,\n",
       "   0.68998,\n",
       "   0.6957,\n",
       "   0.70836,\n",
       "   0.71498,\n",
       "   0.72644,\n",
       "   0.73122,\n",
       "   0.73802,\n",
       "   0.74966,\n",
       "   0.75726,\n",
       "   0.7639,\n",
       "   0.77484,\n",
       "   0.78264,\n",
       "   0.78828,\n",
       "   0.79692,\n",
       "   0.798,\n",
       "   0.80814,\n",
       "   0.8136,\n",
       "   0.82106,\n",
       "   0.8254,\n",
       "   0.83306,\n",
       "   0.8398,\n",
       "   0.84594,\n",
       "   0.84924,\n",
       "   0.85988,\n",
       "   0.86116,\n",
       "   0.86324,\n",
       "   0.86588],\n",
       "  'valid-acc': [0.3476000130176544,\n",
       "   0.447299987077713,\n",
       "   0.420199990272522,\n",
       "   0.46389999985694885,\n",
       "   0.4844000041484833,\n",
       "   0.5019999742507935,\n",
       "   0.507099986076355,\n",
       "   0.5113000273704529,\n",
       "   0.483599990606308,\n",
       "   0.5235000252723694,\n",
       "   0.5263000130653381,\n",
       "   0.5227000117301941,\n",
       "   0.5163999795913696,\n",
       "   0.5388000011444092,\n",
       "   0.5235000252723694,\n",
       "   0.51419997215271,\n",
       "   0.5185999870300293,\n",
       "   0.5194000005722046,\n",
       "   0.54339998960495,\n",
       "   0.5187000036239624,\n",
       "   0.5134999752044678,\n",
       "   0.5368000268936157,\n",
       "   0.5224999785423279,\n",
       "   0.5214999914169312,\n",
       "   0.5288000106811523,\n",
       "   0.5331000089645386,\n",
       "   0.5349000096321106,\n",
       "   0.5385000109672546,\n",
       "   0.5160999894142151,\n",
       "   0.5267999768257141,\n",
       "   0.5410000085830688,\n",
       "   0.5234000086784363,\n",
       "   0.5328999757766724,\n",
       "   0.5386999845504761,\n",
       "   0.5353999733924866,\n",
       "   0.5216000080108643,\n",
       "   0.5313000082969666,\n",
       "   0.5235999822616577,\n",
       "   0.5360999703407288,\n",
       "   0.5367000102996826,\n",
       "   0.5266000032424927,\n",
       "   0.524399995803833,\n",
       "   0.5266000032424927,\n",
       "   0.517300009727478,\n",
       "   0.5267999768257141,\n",
       "   0.520799994468689,\n",
       "   0.5220000147819519,\n",
       "   0.5094000101089478,\n",
       "   0.5260000228881836,\n",
       "   0.5242999792098999]},\n",
       " 'exp-lr-0.001-opt-SGD': {'train-loss': [2.0306089215087892,\n",
       "   1.7984736882781982,\n",
       "   1.7149541367340089,\n",
       "   1.6569335483169556,\n",
       "   1.6093846422576905,\n",
       "   1.5714863737106324,\n",
       "   1.5361075061798095,\n",
       "   1.5069193015289306,\n",
       "   1.478908062400818,\n",
       "   1.4559650264358521,\n",
       "   1.4326270917129516,\n",
       "   1.4095407361984253,\n",
       "   1.386631760826111,\n",
       "   1.3695587426757811,\n",
       "   1.3515957067489623,\n",
       "   1.332518397140503,\n",
       "   1.3141869857406616,\n",
       "   1.29750505027771,\n",
       "   1.2820139056777955,\n",
       "   1.2663514128112794,\n",
       "   1.2522281932449342,\n",
       "   1.2364737953948974,\n",
       "   1.2206567263031005,\n",
       "   1.2075762335968017,\n",
       "   1.194777693195343,\n",
       "   1.1791921159744263,\n",
       "   1.1663456266021728,\n",
       "   1.1518830376434326,\n",
       "   1.1378807901382446,\n",
       "   1.127917243423462,\n",
       "   1.1121962924957276,\n",
       "   1.0980478142547607,\n",
       "   1.0857254415512085,\n",
       "   1.07426039478302,\n",
       "   1.0631732619476317,\n",
       "   1.046485140953064,\n",
       "   1.0379621911239625,\n",
       "   1.0226114040374756,\n",
       "   1.0075356854629516,\n",
       "   0.9986946142196655,\n",
       "   0.9912182312011719,\n",
       "   0.975264813041687,\n",
       "   0.9648205880928039,\n",
       "   0.9512847855377198,\n",
       "   0.9384110261917115,\n",
       "   0.9278045449066162,\n",
       "   0.9110551909255982,\n",
       "   0.8983833460807801,\n",
       "   0.892720341720581,\n",
       "   0.8845045190048217],\n",
       "  'valid-loss': [1.8592470146179199,\n",
       "   1.7489832500457763,\n",
       "   1.6817476560592652,\n",
       "   1.633953771018982,\n",
       "   1.5946252885818482,\n",
       "   1.5750688817977905,\n",
       "   1.5362110397338866,\n",
       "   1.518227336502075,\n",
       "   1.531416907119751,\n",
       "   1.4680850234985352,\n",
       "   1.456498403930664,\n",
       "   1.4389899644851685,\n",
       "   1.4237038917541505,\n",
       "   1.4360055963516236,\n",
       "   1.4168023586273193,\n",
       "   1.4015041650772095,\n",
       "   1.4085928052902221,\n",
       "   1.3786951044082643,\n",
       "   1.372320925140381,\n",
       "   1.3937210855484008,\n",
       "   1.3777553592681884,\n",
       "   1.39726038646698,\n",
       "   1.369632932662964,\n",
       "   1.3580051025390625,\n",
       "   1.3592630317687988,\n",
       "   1.3431883777618407,\n",
       "   1.355437975502014,\n",
       "   1.3343655658721925,\n",
       "   1.3701104301452636,\n",
       "   1.3952062831878662,\n",
       "   1.3549670389175414,\n",
       "   1.3373027565002442,\n",
       "   1.3622272811889649,\n",
       "   1.3510140617370605,\n",
       "   1.3819687713623048,\n",
       "   1.3855565856933594,\n",
       "   1.342325555038452,\n",
       "   1.340740579032898,\n",
       "   1.3570503196716308,\n",
       "   1.3954750509262086,\n",
       "   1.4004708305358886,\n",
       "   1.3786253757476807,\n",
       "   1.3248135726928711,\n",
       "   1.36388009223938,\n",
       "   1.3517924892425537,\n",
       "   1.4786868070602417,\n",
       "   1.4162540260314942,\n",
       "   1.4456856327056884,\n",
       "   1.3798736824035644,\n",
       "   1.3869289447784423],\n",
       "  'train-acc': [0.2726,\n",
       "   0.36744,\n",
       "   0.3993,\n",
       "   0.4186,\n",
       "   0.4352,\n",
       "   0.44844,\n",
       "   0.45952,\n",
       "   0.4706,\n",
       "   0.47836,\n",
       "   0.49006,\n",
       "   0.49634,\n",
       "   0.5034,\n",
       "   0.51136,\n",
       "   0.51842,\n",
       "   0.5234,\n",
       "   0.52962,\n",
       "   0.5371,\n",
       "   0.54316,\n",
       "   0.5487,\n",
       "   0.55354,\n",
       "   0.55874,\n",
       "   0.56538,\n",
       "   0.56936,\n",
       "   0.57438,\n",
       "   0.57882,\n",
       "   0.58486,\n",
       "   0.5891,\n",
       "   0.5945,\n",
       "   0.6002,\n",
       "   0.60192,\n",
       "   0.61108,\n",
       "   0.61238,\n",
       "   0.61966,\n",
       "   0.62294,\n",
       "   0.62508,\n",
       "   0.63246,\n",
       "   0.63686,\n",
       "   0.63956,\n",
       "   0.64612,\n",
       "   0.64996,\n",
       "   0.65192,\n",
       "   0.66058,\n",
       "   0.66256,\n",
       "   0.66566,\n",
       "   0.6711,\n",
       "   0.67528,\n",
       "   0.68234,\n",
       "   0.68454,\n",
       "   0.68872,\n",
       "   0.69108],\n",
       "  'valid-acc': [0.3443000018596649,\n",
       "   0.38199999928474426,\n",
       "   0.40790000557899475,\n",
       "   0.4262000024318695,\n",
       "   0.44179999828338623,\n",
       "   0.4480000138282776,\n",
       "   0.45829999446868896,\n",
       "   0.46389999985694885,\n",
       "   0.4648999869823456,\n",
       "   0.4790000021457672,\n",
       "   0.4887999892234802,\n",
       "   0.4860000014305115,\n",
       "   0.4952000081539154,\n",
       "   0.49000000953674316,\n",
       "   0.4941999912261963,\n",
       "   0.5034999847412109,\n",
       "   0.5,\n",
       "   0.5098000168800354,\n",
       "   0.5105999708175659,\n",
       "   0.5087000131607056,\n",
       "   0.5077999830245972,\n",
       "   0.5022000074386597,\n",
       "   0.5144000053405762,\n",
       "   0.5163000226020813,\n",
       "   0.5184000134468079,\n",
       "   0.5178999900817871,\n",
       "   0.5171999931335449,\n",
       "   0.5307999849319458,\n",
       "   0.5188000202178955,\n",
       "   0.5073999762535095,\n",
       "   0.5248000025749207,\n",
       "   0.5285000205039978,\n",
       "   0.5175999999046326,\n",
       "   0.5246000289916992,\n",
       "   0.5166000127792358,\n",
       "   0.5115000009536743,\n",
       "   0.5295000076293945,\n",
       "   0.5307999849319458,\n",
       "   0.527899980545044,\n",
       "   0.5200999975204468,\n",
       "   0.516700029373169,\n",
       "   0.5239999890327454,\n",
       "   0.5418000221252441,\n",
       "   0.5321000218391418,\n",
       "   0.5324000120162964,\n",
       "   0.5019999742507935,\n",
       "   0.5227000117301941,\n",
       "   0.5148000121116638,\n",
       "   0.5321000218391418,\n",
       "   0.5321999788284302]},\n",
       " 'exp-lr-0.1-opt-RMSprop': {'train-loss': [18236.63001866745,\n",
       "   2.3085197195434572,\n",
       "   2.3074983016204835,\n",
       "   2.3079149768066407,\n",
       "   2.3078556884765624,\n",
       "   2.30770846786499,\n",
       "   2.3081307846069334,\n",
       "   2.3077432322692872,\n",
       "   2.3082394480895996,\n",
       "   2.3078946664428712,\n",
       "   2.3077396141052247,\n",
       "   2.307694238204956,\n",
       "   2.3080608409118653,\n",
       "   2.307800756149292,\n",
       "   2.3074918619537352,\n",
       "   2.3077693394470216,\n",
       "   2.30805646774292,\n",
       "   2.307911833572388,\n",
       "   2.3082556196594237,\n",
       "   2.308219700317383,\n",
       "   2.3082287245178224,\n",
       "   2.307881343994141,\n",
       "   2.3079716454315187,\n",
       "   2.3081313960266114,\n",
       "   2.3076533540344237,\n",
       "   2.30812430229187,\n",
       "   2.307927504348755,\n",
       "   2.3076847734069825,\n",
       "   2.307257461013794,\n",
       "   2.3074808418273927,\n",
       "   2.3080542012786864,\n",
       "   2.3075179357147215,\n",
       "   2.3078030754089354,\n",
       "   2.30782341003418,\n",
       "   2.3081678201293947,\n",
       "   2.308140376739502,\n",
       "   2.30787939163208,\n",
       "   2.3074231804656984,\n",
       "   2.307664676437378,\n",
       "   2.307533048629761,\n",
       "   2.3078974843597413,\n",
       "   2.3077630371856688,\n",
       "   2.3079015068817137,\n",
       "   2.307781506958008,\n",
       "   2.307809752960205,\n",
       "   2.3077628688049314,\n",
       "   2.307771495819092,\n",
       "   2.3078738813018798,\n",
       "   2.307761044845581,\n",
       "   2.3075646575164797],\n",
       "  'valid-loss': [2.328194737625122,\n",
       "   2.3062500926971436,\n",
       "   2.308404620361328,\n",
       "   2.3110299587249754,\n",
       "   2.3207990440368653,\n",
       "   2.309222889328003,\n",
       "   2.3112367538452148,\n",
       "   2.312670278930664,\n",
       "   2.310402252960205,\n",
       "   2.307768556976318,\n",
       "   2.3140917152404783,\n",
       "   2.316845660018921,\n",
       "   2.311844073486328,\n",
       "   2.3122795124053956,\n",
       "   2.3137574546813964,\n",
       "   2.3167108863830568,\n",
       "   2.3130141258239747,\n",
       "   2.3118388984680176,\n",
       "   2.309109992980957,\n",
       "   2.3094503860473634,\n",
       "   2.310088740539551,\n",
       "   2.3096949085235594,\n",
       "   2.315390168762207,\n",
       "   2.3130242012023925,\n",
       "   2.316224026489258,\n",
       "   2.309923371887207,\n",
       "   2.315563619995117,\n",
       "   2.31879986038208,\n",
       "   2.308992776107788,\n",
       "   2.3059267124176026,\n",
       "   2.3130324363708494,\n",
       "   2.306936831665039,\n",
       "   2.313263011932373,\n",
       "   2.313833126831055,\n",
       "   2.3059130165100097,\n",
       "   2.307869319152832,\n",
       "   2.3219059051513673,\n",
       "   2.3185225631713866,\n",
       "   2.317840007019043,\n",
       "   2.3200453701019286,\n",
       "   2.3161942947387697,\n",
       "   2.3143586051940916,\n",
       "   2.316277624130249,\n",
       "   2.315734609222412,\n",
       "   2.313947141265869,\n",
       "   2.309992337799072,\n",
       "   2.3170366554260253,\n",
       "   2.3094734535217287,\n",
       "   2.3105222492218016,\n",
       "   2.3151266929626466],\n",
       "  'train-acc': [0.09848,\n",
       "   0.0983,\n",
       "   0.10134,\n",
       "   0.09938,\n",
       "   0.09928,\n",
       "   0.09984,\n",
       "   0.09852,\n",
       "   0.10036,\n",
       "   0.09842,\n",
       "   0.0988,\n",
       "   0.10264,\n",
       "   0.1,\n",
       "   0.09964,\n",
       "   0.09812,\n",
       "   0.10266,\n",
       "   0.10186,\n",
       "   0.09808,\n",
       "   0.10004,\n",
       "   0.09712,\n",
       "   0.09974,\n",
       "   0.099,\n",
       "   0.10018,\n",
       "   0.10094,\n",
       "   0.09972,\n",
       "   0.10042,\n",
       "   0.09842,\n",
       "   0.09752,\n",
       "   0.09996,\n",
       "   0.10254,\n",
       "   0.10318,\n",
       "   0.09686,\n",
       "   0.10088,\n",
       "   0.0995,\n",
       "   0.09922,\n",
       "   0.09668,\n",
       "   0.10002,\n",
       "   0.09984,\n",
       "   0.09876,\n",
       "   0.10092,\n",
       "   0.10004,\n",
       "   0.09908,\n",
       "   0.09954,\n",
       "   0.09892,\n",
       "   0.10056,\n",
       "   0.09918,\n",
       "   0.09982,\n",
       "   0.09962,\n",
       "   0.10114,\n",
       "   0.10258,\n",
       "   0.0993],\n",
       "  'valid-acc': [0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612]},\n",
       " 'exp-lr-0.01-opt-RMSprop': {'train-loss': [8.707019654464721,\n",
       "   2.3328791647338867,\n",
       "   2.1645827758789062,\n",
       "   2.0958985050201417,\n",
       "   2.052641410675049,\n",
       "   1.9920418160247804,\n",
       "   1.9567522735595704,\n",
       "   1.9356505054473876,\n",
       "   1.921232006149292,\n",
       "   1.9073103565216065,\n",
       "   1.8979138858795166,\n",
       "   1.8870378589248658,\n",
       "   1.8739857410049439,\n",
       "   1.8625859723281861,\n",
       "   1.8597059295272826,\n",
       "   1.8522924365997315,\n",
       "   1.8497109957122804,\n",
       "   1.8454202968215943,\n",
       "   1.840399379234314,\n",
       "   1.842897724342346,\n",
       "   1.8404417174911498,\n",
       "   1.8343492809295654,\n",
       "   1.8357590479278565,\n",
       "   1.8282695202255248,\n",
       "   1.8309529583358766,\n",
       "   1.8259517126464844,\n",
       "   1.820301167564392,\n",
       "   1.8243633325958253,\n",
       "   1.8205985712432862,\n",
       "   1.819067412109375,\n",
       "   1.8207737432479858,\n",
       "   1.8169845300674439,\n",
       "   1.8166207706451416,\n",
       "   1.8159770262527466,\n",
       "   1.8116858206558228,\n",
       "   1.811500941772461,\n",
       "   1.8114802465438842,\n",
       "   1.8077247974395751,\n",
       "   1.8107103044891357,\n",
       "   1.8048079736328124,\n",
       "   1.803976206626892,\n",
       "   1.8053598342895507,\n",
       "   1.8052296788787843,\n",
       "   1.8081643402862548,\n",
       "   1.8018372954940796,\n",
       "   1.805726517944336,\n",
       "   1.8022580281829834,\n",
       "   1.8036833867645263,\n",
       "   1.7995979699707032,\n",
       "   1.7986814667129516],\n",
       "  'valid-loss': [2.3028179183959963,\n",
       "   2.177898131942749,\n",
       "   2.093387284660339,\n",
       "   2.053855276298523,\n",
       "   2.027649240875244,\n",
       "   2.0767971759796144,\n",
       "   1.9021941795349122,\n",
       "   1.9837081840515136,\n",
       "   1.9802747802734375,\n",
       "   2.048100785636902,\n",
       "   2.100511989974976,\n",
       "   2.149562200164795,\n",
       "   2.028545891952515,\n",
       "   1.8726868783950805,\n",
       "   1.9381883396148682,\n",
       "   1.8632560848236084,\n",
       "   1.8963823764801024,\n",
       "   2.1083050306320192,\n",
       "   1.8264114124298096,\n",
       "   1.8454545558929443,\n",
       "   1.9224172832489013,\n",
       "   1.9155893003463744,\n",
       "   1.8665124237060546,\n",
       "   1.905245267868042,\n",
       "   2.08717877368927,\n",
       "   1.8385816467285157,\n",
       "   1.813295041847229,\n",
       "   1.8505317008972169,\n",
       "   1.9290479843139647,\n",
       "   1.8322115776062011,\n",
       "   1.8272856590270996,\n",
       "   1.7997214889526367,\n",
       "   2.086052400588989,\n",
       "   1.8147150928497315,\n",
       "   1.8070065963745117,\n",
       "   1.9223396270751953,\n",
       "   1.8132369010925293,\n",
       "   1.9129946159362794,\n",
       "   1.846523980140686,\n",
       "   1.7974880271911622,\n",
       "   1.8532825801849366,\n",
       "   1.8484994285583496,\n",
       "   1.8466921764373778,\n",
       "   1.84459926738739,\n",
       "   1.801686548614502,\n",
       "   1.792052515411377,\n",
       "   1.8385024660110474,\n",
       "   2.030289410018921,\n",
       "   1.8023278987884521,\n",
       "   1.8614155029296875],\n",
       "  'train-acc': [0.1065,\n",
       "   0.10552,\n",
       "   0.16846,\n",
       "   0.18502,\n",
       "   0.21288,\n",
       "   0.25124,\n",
       "   0.26856,\n",
       "   0.27356,\n",
       "   0.28012,\n",
       "   0.28822,\n",
       "   0.294,\n",
       "   0.29768,\n",
       "   0.30044,\n",
       "   0.3062,\n",
       "   0.30966,\n",
       "   0.31304,\n",
       "   0.31388,\n",
       "   0.31194,\n",
       "   0.31454,\n",
       "   0.31208,\n",
       "   0.31292,\n",
       "   0.31818,\n",
       "   0.31372,\n",
       "   0.3182,\n",
       "   0.31818,\n",
       "   0.31974,\n",
       "   0.32386,\n",
       "   0.31922,\n",
       "   0.32478,\n",
       "   0.32264,\n",
       "   0.32212,\n",
       "   0.32512,\n",
       "   0.32306,\n",
       "   0.32572,\n",
       "   0.32454,\n",
       "   0.32504,\n",
       "   0.32566,\n",
       "   0.32916,\n",
       "   0.32708,\n",
       "   0.3297,\n",
       "   0.332,\n",
       "   0.32882,\n",
       "   0.32534,\n",
       "   0.3281,\n",
       "   0.3282,\n",
       "   0.32618,\n",
       "   0.32902,\n",
       "   0.32936,\n",
       "   0.3296,\n",
       "   0.3275],\n",
       "  'valid-acc': [0.10000000149011612,\n",
       "   0.1817999929189682,\n",
       "   0.17249999940395355,\n",
       "   0.19130000472068787,\n",
       "   0.2093999981880188,\n",
       "   0.2264000028371811,\n",
       "   0.2849999964237213,\n",
       "   0.25859999656677246,\n",
       "   0.2565999925136566,\n",
       "   0.2587999999523163,\n",
       "   0.23520000278949738,\n",
       "   0.25130000710487366,\n",
       "   0.25940001010894775,\n",
       "   0.30250000953674316,\n",
       "   0.27869999408721924,\n",
       "   0.3125999867916107,\n",
       "   0.29440000653266907,\n",
       "   0.24940000474452972,\n",
       "   0.3127000033855438,\n",
       "   0.30559998750686646,\n",
       "   0.3057999908924103,\n",
       "   0.29109999537467957,\n",
       "   0.2985000014305115,\n",
       "   0.28630000352859497,\n",
       "   0.27880001068115234,\n",
       "   0.30959999561309814,\n",
       "   0.3231000006198883,\n",
       "   0.3131999969482422,\n",
       "   0.30149999260902405,\n",
       "   0.31949999928474426,\n",
       "   0.3190999925136566,\n",
       "   0.3278999924659729,\n",
       "   0.24320000410079956,\n",
       "   0.3199999928474426,\n",
       "   0.3278999924659729,\n",
       "   0.296099990606308,\n",
       "   0.32519999146461487,\n",
       "   0.29649999737739563,\n",
       "   0.31130000948905945,\n",
       "   0.32409998774528503,\n",
       "   0.31769999861717224,\n",
       "   0.30550000071525574,\n",
       "   0.3046000003814697,\n",
       "   0.31459999084472656,\n",
       "   0.32510000467300415,\n",
       "   0.33219999074935913,\n",
       "   0.31470000743865967,\n",
       "   0.27149999141693115,\n",
       "   0.3206999897956848,\n",
       "   0.30630001425743103]},\n",
       " 'exp-lr-0.001-opt-RMSprop': {'train-loss': [2.2902120139312743,\n",
       "   1.8843598670196533,\n",
       "   1.782829172744751,\n",
       "   1.7124327630615235,\n",
       "   1.6567784759521484,\n",
       "   1.6103243775177003,\n",
       "   1.5756549105072022,\n",
       "   1.5361812021636962,\n",
       "   1.5004870419692993,\n",
       "   1.477168139038086,\n",
       "   1.4479081517791748,\n",
       "   1.4206277968215943,\n",
       "   1.3944462480926514,\n",
       "   1.3698980298233032,\n",
       "   1.348729182510376,\n",
       "   1.3258040807342528,\n",
       "   1.303020569114685,\n",
       "   1.2839038552856445,\n",
       "   1.261347911453247,\n",
       "   1.2353994139862061,\n",
       "   1.2144139801406861,\n",
       "   1.1965180560684203,\n",
       "   1.1799187149047852,\n",
       "   1.1547810105133056,\n",
       "   1.1332561880111693,\n",
       "   1.1188621488189698,\n",
       "   1.1023349547576904,\n",
       "   1.0784885449600219,\n",
       "   1.063628548851013,\n",
       "   1.0421142546844482,\n",
       "   1.0306626638793945,\n",
       "   1.010342085723877,\n",
       "   0.9996495610427857,\n",
       "   0.9788630319595337,\n",
       "   0.9622936516571045,\n",
       "   0.9515251315307617,\n",
       "   0.9365133645439148,\n",
       "   0.9145959563827515,\n",
       "   0.9070465286445618,\n",
       "   0.8886559008789062,\n",
       "   0.8763496699905395,\n",
       "   0.8630750935554504,\n",
       "   0.8489638731002808,\n",
       "   0.8360218033981324,\n",
       "   0.8228212997245788,\n",
       "   0.8121086391830444,\n",
       "   0.7976536003112793,\n",
       "   0.7852460512161255,\n",
       "   0.7773828754425048,\n",
       "   0.7663879692459107],\n",
       "  'valid-loss': [2.0809662244796754,\n",
       "   1.8574581382751465,\n",
       "   1.74860599193573,\n",
       "   1.7671780075073242,\n",
       "   1.6546227899551391,\n",
       "   1.8693656955718994,\n",
       "   1.618953847503662,\n",
       "   1.8298178655624389,\n",
       "   1.864852089691162,\n",
       "   1.637045791053772,\n",
       "   1.5701075675964355,\n",
       "   1.6815869430541992,\n",
       "   1.4820979885101317,\n",
       "   1.5632610816955566,\n",
       "   1.5917411422729493,\n",
       "   1.5262853509902954,\n",
       "   1.7079641708374023,\n",
       "   1.620271718597412,\n",
       "   1.5097856712341309,\n",
       "   1.4879205249786378,\n",
       "   1.5909811058044434,\n",
       "   1.6284987636566162,\n",
       "   1.5440753562927245,\n",
       "   1.5583026119232177,\n",
       "   1.548586533355713,\n",
       "   1.644426148223877,\n",
       "   1.479251427078247,\n",
       "   1.6113549140930177,\n",
       "   1.6493629566192627,\n",
       "   1.6196521240234374,\n",
       "   1.7949809631347655,\n",
       "   1.6274643348693847,\n",
       "   1.6633226028442383,\n",
       "   1.5915774326324463,\n",
       "   1.6455045848846435,\n",
       "   1.7679744705200195,\n",
       "   1.6088696090698242,\n",
       "   1.7941178230285644,\n",
       "   1.7028830348968507,\n",
       "   1.7921957782745361,\n",
       "   1.795018947982788,\n",
       "   1.7721813873291015,\n",
       "   1.8698719596862794,\n",
       "   1.9814908977508545,\n",
       "   1.8452876468658448,\n",
       "   1.953824102783203,\n",
       "   1.858508805847168,\n",
       "   1.9287504508972169,\n",
       "   1.9963398559570313,\n",
       "   1.9660408378601075],\n",
       "  'train-acc': [0.21034,\n",
       "   0.31816,\n",
       "   0.3591,\n",
       "   0.38562,\n",
       "   0.40892,\n",
       "   0.42342,\n",
       "   0.43728,\n",
       "   0.4527,\n",
       "   0.4633,\n",
       "   0.4728,\n",
       "   0.48262,\n",
       "   0.4943,\n",
       "   0.50416,\n",
       "   0.50836,\n",
       "   0.52082,\n",
       "   0.52674,\n",
       "   0.53594,\n",
       "   0.54298,\n",
       "   0.5508,\n",
       "   0.56142,\n",
       "   0.56712,\n",
       "   0.57302,\n",
       "   0.57742,\n",
       "   0.58784,\n",
       "   0.5971,\n",
       "   0.60118,\n",
       "   0.60514,\n",
       "   0.6141,\n",
       "   0.6209,\n",
       "   0.62982,\n",
       "   0.63108,\n",
       "   0.63814,\n",
       "   0.64142,\n",
       "   0.64848,\n",
       "   0.65856,\n",
       "   0.66128,\n",
       "   0.66648,\n",
       "   0.67128,\n",
       "   0.67478,\n",
       "   0.68204,\n",
       "   0.68586,\n",
       "   0.69006,\n",
       "   0.69418,\n",
       "   0.69808,\n",
       "   0.70442,\n",
       "   0.7099,\n",
       "   0.71194,\n",
       "   0.7182,\n",
       "   0.72136,\n",
       "   0.72526],\n",
       "  'valid-acc': [0.24050000309944153,\n",
       "   0.325300008058548,\n",
       "   0.367900013923645,\n",
       "   0.37880000472068787,\n",
       "   0.41519999504089355,\n",
       "   0.35749998688697815,\n",
       "   0.428600013256073,\n",
       "   0.3813000023365021,\n",
       "   0.37610000371932983,\n",
       "   0.41449999809265137,\n",
       "   0.43950000405311584,\n",
       "   0.3970000147819519,\n",
       "   0.46860000491142273,\n",
       "   0.4399999976158142,\n",
       "   0.4487999975681305,\n",
       "   0.46129998564720154,\n",
       "   0.415800005197525,\n",
       "   0.4357999861240387,\n",
       "   0.47029998898506165,\n",
       "   0.49300000071525574,\n",
       "   0.4429999887943268,\n",
       "   0.450300008058548,\n",
       "   0.4878000020980835,\n",
       "   0.477400004863739,\n",
       "   0.4781999886035919,\n",
       "   0.4580000042915344,\n",
       "   0.5030999779701233,\n",
       "   0.47760000824928284,\n",
       "   0.48030000925064087,\n",
       "   0.45809999108314514,\n",
       "   0.4603999853134155,\n",
       "   0.4844000041484833,\n",
       "   0.4724999964237213,\n",
       "   0.48410001397132874,\n",
       "   0.4846999943256378,\n",
       "   0.47029998898506165,\n",
       "   0.5009999871253967,\n",
       "   0.482699990272522,\n",
       "   0.48579999804496765,\n",
       "   0.4742000102996826,\n",
       "   0.48590001463890076,\n",
       "   0.48750001192092896,\n",
       "   0.4674000144004822,\n",
       "   0.4745999872684479,\n",
       "   0.4925000071525574,\n",
       "   0.4844000041484833,\n",
       "   0.48969998955726624,\n",
       "   0.45419999957084656,\n",
       "   0.48420000076293945,\n",
       "   0.4620000123977661]},\n",
       " 'exp-lr-0.1-opt-Adagrad': {'train-loss': [186.84667162918092,\n",
       "   2.195129744338989,\n",
       "   2.1184910051727295,\n",
       "   2.0619466919708254,\n",
       "   2.0148829516220093,\n",
       "   1.9769321532440185,\n",
       "   1.9375502828598024,\n",
       "   1.8784787951278688,\n",
       "   1.8273904592132568,\n",
       "   1.7902294268035888,\n",
       "   1.763855680770874,\n",
       "   1.743430718421936,\n",
       "   1.724390114440918,\n",
       "   1.7048202187728883,\n",
       "   1.6878809957885743,\n",
       "   1.678463749961853,\n",
       "   1.6625782077026368,\n",
       "   1.6476100229263306,\n",
       "   1.6373291655731201,\n",
       "   1.62132808467865,\n",
       "   1.6109198056411742,\n",
       "   1.5966729664993287,\n",
       "   1.5950850963592529,\n",
       "   1.579378943862915,\n",
       "   1.5759132455444336,\n",
       "   1.561579169998169,\n",
       "   1.557466993751526,\n",
       "   1.547327730140686,\n",
       "   1.5381370769500733,\n",
       "   1.532660271987915,\n",
       "   1.525172714767456,\n",
       "   1.5193682318878174,\n",
       "   1.5138257248687743,\n",
       "   1.5061046449279785,\n",
       "   1.5044924908065795,\n",
       "   1.4943111303710936,\n",
       "   1.4896120732879639,\n",
       "   1.4838657763290406,\n",
       "   1.476199009628296,\n",
       "   1.469158291244507,\n",
       "   1.4671376492309571,\n",
       "   1.4628790076065064,\n",
       "   1.4578160749053954,\n",
       "   1.4507362785720825,\n",
       "   1.4469495707321167,\n",
       "   1.4397655112075807,\n",
       "   1.4382004694366455,\n",
       "   1.4352928217315675,\n",
       "   1.43081698387146,\n",
       "   1.421664661140442],\n",
       "  'valid-loss': [2.276486238861084,\n",
       "   2.166381467819214,\n",
       "   2.175714518928528,\n",
       "   2.0703719680786135,\n",
       "   1.991467533302307,\n",
       "   2.1289106925964356,\n",
       "   1.9289194124221802,\n",
       "   1.858003468322754,\n",
       "   1.92571254863739,\n",
       "   1.8214503391265868,\n",
       "   1.8043736995697022,\n",
       "   1.7578230375289916,\n",
       "   1.849982103729248,\n",
       "   1.8374601028442383,\n",
       "   1.8484901313781739,\n",
       "   1.7510592453002929,\n",
       "   1.7960920253753663,\n",
       "   1.6918507621765138,\n",
       "   1.712299956893921,\n",
       "   1.691923938369751,\n",
       "   1.7051841690063476,\n",
       "   1.6743819240570068,\n",
       "   1.6776958328247071,\n",
       "   1.618685708618164,\n",
       "   1.6247802349090577,\n",
       "   1.6374876571655272,\n",
       "   1.6177118270874022,\n",
       "   1.6853403814315795,\n",
       "   1.6295143117904662,\n",
       "   1.6998975624084474,\n",
       "   1.599021169281006,\n",
       "   1.578056090927124,\n",
       "   1.620108984375,\n",
       "   1.6921946678161621,\n",
       "   1.6094694889068604,\n",
       "   1.6141978271484374,\n",
       "   1.5995531787872315,\n",
       "   1.5875634452819825,\n",
       "   1.6437356342315674,\n",
       "   1.5968566883087159,\n",
       "   1.5744866022109985,\n",
       "   1.8681778984069823,\n",
       "   1.617411064338684,\n",
       "   1.6559597450256347,\n",
       "   1.5728201251983642,\n",
       "   1.5908268852233887,\n",
       "   1.546253968811035,\n",
       "   1.5496112201690675,\n",
       "   1.5499121755599976,\n",
       "   1.5466175378799438],\n",
       "  'train-acc': [0.12042,\n",
       "   0.17044,\n",
       "   0.20256,\n",
       "   0.22546,\n",
       "   0.243,\n",
       "   0.26306,\n",
       "   0.28852,\n",
       "   0.31938,\n",
       "   0.3425,\n",
       "   0.35796,\n",
       "   0.36754,\n",
       "   0.3764,\n",
       "   0.38212,\n",
       "   0.38896,\n",
       "   0.39608,\n",
       "   0.39956,\n",
       "   0.40648,\n",
       "   0.40986,\n",
       "   0.41588,\n",
       "   0.42246,\n",
       "   0.42292,\n",
       "   0.4307,\n",
       "   0.4283,\n",
       "   0.4346,\n",
       "   0.43626,\n",
       "   0.44058,\n",
       "   0.44318,\n",
       "   0.44512,\n",
       "   0.45382,\n",
       "   0.45236,\n",
       "   0.45422,\n",
       "   0.45728,\n",
       "   0.45848,\n",
       "   0.46182,\n",
       "   0.46356,\n",
       "   0.46408,\n",
       "   0.46726,\n",
       "   0.47,\n",
       "   0.47116,\n",
       "   0.47474,\n",
       "   0.4739,\n",
       "   0.47828,\n",
       "   0.47828,\n",
       "   0.48356,\n",
       "   0.48246,\n",
       "   0.48822,\n",
       "   0.48562,\n",
       "   0.48766,\n",
       "   0.48906,\n",
       "   0.49166],\n",
       "  'valid-acc': [0.11739999800920486,\n",
       "   0.17880000174045563,\n",
       "   0.18070000410079956,\n",
       "   0.21539999544620514,\n",
       "   0.25609999895095825,\n",
       "   0.20080000162124634,\n",
       "   0.304500013589859,\n",
       "   0.3303000032901764,\n",
       "   0.30630001425743103,\n",
       "   0.34310001134872437,\n",
       "   0.3465000092983246,\n",
       "   0.37959998846054077,\n",
       "   0.33309999108314514,\n",
       "   0.34599998593330383,\n",
       "   0.33379998803138733,\n",
       "   0.37770000100135803,\n",
       "   0.3555999994277954,\n",
       "   0.38839998841285706,\n",
       "   0.3939000070095062,\n",
       "   0.4004000127315521,\n",
       "   0.3937999904155731,\n",
       "   0.40450000762939453,\n",
       "   0.41339999437332153,\n",
       "   0.4255000054836273,\n",
       "   0.4203000068664551,\n",
       "   0.4207000136375427,\n",
       "   0.4212999939918518,\n",
       "   0.40049999952316284,\n",
       "   0.4196000099182129,\n",
       "   0.39649999141693115,\n",
       "   0.43059998750686646,\n",
       "   0.4366999864578247,\n",
       "   0.42089998722076416,\n",
       "   0.4108999967575073,\n",
       "   0.42809998989105225,\n",
       "   0.42719998955726624,\n",
       "   0.4359000027179718,\n",
       "   0.44110000133514404,\n",
       "   0.41929998993873596,\n",
       "   0.4309000074863434,\n",
       "   0.44209998846054077,\n",
       "   0.3614000082015991,\n",
       "   0.4325000047683716,\n",
       "   0.41990000009536743,\n",
       "   0.44510000944137573,\n",
       "   0.44279998540878296,\n",
       "   0.45249998569488525,\n",
       "   0.4564000070095062,\n",
       "   0.4496000111103058,\n",
       "   0.45419999957084656]},\n",
       " 'exp-lr-0.01-opt-Adagrad': {'train-loss': [2.844168552474976,\n",
       "   1.8134314081573486,\n",
       "   1.7240124573135376,\n",
       "   1.6566199213027955,\n",
       "   1.612609351234436,\n",
       "   1.5698098979187012,\n",
       "   1.5368184469604491,\n",
       "   1.5105032118988038,\n",
       "   1.4843623123931884,\n",
       "   1.4598009281158448,\n",
       "   1.43777349861145,\n",
       "   1.4206559432220458,\n",
       "   1.4032907608413696,\n",
       "   1.3857541209793092,\n",
       "   1.3718325283432007,\n",
       "   1.3541099851226808,\n",
       "   1.337764119644165,\n",
       "   1.3284941611099244,\n",
       "   1.3112848361968994,\n",
       "   1.3012090857696532,\n",
       "   1.290159489212036,\n",
       "   1.2785345392227172,\n",
       "   1.2649795174407958,\n",
       "   1.2596023171234132,\n",
       "   1.2421168161010743,\n",
       "   1.2303452729415894,\n",
       "   1.2248030284500122,\n",
       "   1.2105277026367187,\n",
       "   1.2045625201797485,\n",
       "   1.1915646561813356,\n",
       "   1.18232814743042,\n",
       "   1.1777333879852294,\n",
       "   1.1648273169708252,\n",
       "   1.1577738938903808,\n",
       "   1.1473744225692748,\n",
       "   1.1410935357284546,\n",
       "   1.1328542071914673,\n",
       "   1.122621173324585,\n",
       "   1.114206778945923,\n",
       "   1.1091023440742493,\n",
       "   1.0971737736320495,\n",
       "   1.0954271215057374,\n",
       "   1.0822037134552003,\n",
       "   1.0776877453231812,\n",
       "   1.0682321530151366,\n",
       "   1.0644722883987427,\n",
       "   1.055495708732605,\n",
       "   1.0487634719467163,\n",
       "   1.042483076915741,\n",
       "   1.034986860370636],\n",
       "  'valid-loss': [2.185423492050171,\n",
       "   1.7844167627334595,\n",
       "   1.7136604454040527,\n",
       "   1.6587255611419678,\n",
       "   1.6127262861251832,\n",
       "   1.6976814573287964,\n",
       "   1.5353600933074951,\n",
       "   1.5800045921325683,\n",
       "   1.5533586814880371,\n",
       "   1.5101259048461915,\n",
       "   1.522973782348633,\n",
       "   1.5067797107696532,\n",
       "   1.482520029449463,\n",
       "   1.480270343017578,\n",
       "   1.5140133855819702,\n",
       "   1.4730857357025147,\n",
       "   1.5219621341705323,\n",
       "   1.4500617397308349,\n",
       "   1.4430563093185425,\n",
       "   1.4686696182250976,\n",
       "   1.4226849941253663,\n",
       "   1.4589442068099976,\n",
       "   1.4147667739868164,\n",
       "   1.4439741142272948,\n",
       "   1.4189178806304932,\n",
       "   1.534383702659607,\n",
       "   1.4100119552612305,\n",
       "   1.4148383808135987,\n",
       "   1.3887289611816407,\n",
       "   1.4695468057632446,\n",
       "   1.4749758350372315,\n",
       "   1.4129786155700683,\n",
       "   1.390255735206604,\n",
       "   1.4253645376205444,\n",
       "   1.4010851207733155,\n",
       "   1.377000382232666,\n",
       "   1.3791167776107789,\n",
       "   1.3573499946594239,\n",
       "   1.3760177515029908,\n",
       "   1.3871943901062012,\n",
       "   1.4225982803344726,\n",
       "   1.3744294441223144,\n",
       "   1.5067969398498535,\n",
       "   1.4122413902282716,\n",
       "   1.3644072225570678,\n",
       "   1.3484760513305665,\n",
       "   1.3866502716064453,\n",
       "   1.4042561981201171,\n",
       "   1.3710226936340333,\n",
       "   1.4060601039886476],\n",
       "  'train-acc': [0.25456,\n",
       "   0.3496,\n",
       "   0.3858,\n",
       "   0.41012,\n",
       "   0.42834,\n",
       "   0.44214,\n",
       "   0.45646,\n",
       "   0.4634,\n",
       "   0.47264,\n",
       "   0.48472,\n",
       "   0.4924,\n",
       "   0.49676,\n",
       "   0.50508,\n",
       "   0.50984,\n",
       "   0.51586,\n",
       "   0.52162,\n",
       "   0.5278,\n",
       "   0.53056,\n",
       "   0.53604,\n",
       "   0.54208,\n",
       "   0.54622,\n",
       "   0.5491,\n",
       "   0.55296,\n",
       "   0.55622,\n",
       "   0.56238,\n",
       "   0.5658,\n",
       "   0.57008,\n",
       "   0.57432,\n",
       "   0.5768,\n",
       "   0.57978,\n",
       "   0.58402,\n",
       "   0.58608,\n",
       "   0.5887,\n",
       "   0.59302,\n",
       "   0.5972,\n",
       "   0.59948,\n",
       "   0.6006,\n",
       "   0.60648,\n",
       "   0.60886,\n",
       "   0.61076,\n",
       "   0.6147,\n",
       "   0.61566,\n",
       "   0.61968,\n",
       "   0.62194,\n",
       "   0.62732,\n",
       "   0.62844,\n",
       "   0.62928,\n",
       "   0.63364,\n",
       "   0.63576,\n",
       "   0.639],\n",
       "  'valid-acc': [0.2370000034570694,\n",
       "   0.35600000619888306,\n",
       "   0.38830000162124634,\n",
       "   0.4052000045776367,\n",
       "   0.42239999771118164,\n",
       "   0.39809998869895935,\n",
       "   0.453900009393692,\n",
       "   0.4343000054359436,\n",
       "   0.4408999979496002,\n",
       "   0.4562000036239624,\n",
       "   0.45509999990463257,\n",
       "   0.4645000100135803,\n",
       "   0.47279998660087585,\n",
       "   0.4724000096321106,\n",
       "   0.462799996137619,\n",
       "   0.48010000586509705,\n",
       "   0.4659000039100647,\n",
       "   0.48579999804496765,\n",
       "   0.48089998960494995,\n",
       "   0.47769999504089355,\n",
       "   0.48980000615119934,\n",
       "   0.48570001125335693,\n",
       "   0.49630001187324524,\n",
       "   0.4767000079154968,\n",
       "   0.4936999976634979,\n",
       "   0.4706999957561493,\n",
       "   0.5059000253677368,\n",
       "   0.504800021648407,\n",
       "   0.5103999972343445,\n",
       "   0.4862000048160553,\n",
       "   0.47909998893737793,\n",
       "   0.5097000002861023,\n",
       "   0.5091999769210815,\n",
       "   0.5109000205993652,\n",
       "   0.5130000114440918,\n",
       "   0.5182999968528748,\n",
       "   0.5177000164985657,\n",
       "   0.5228999853134155,\n",
       "   0.5200999975204468,\n",
       "   0.5156000256538391,\n",
       "   0.5083000063896179,\n",
       "   0.5184000134468079,\n",
       "   0.49050000309944153,\n",
       "   0.5133000016212463,\n",
       "   0.5249000191688538,\n",
       "   0.5304999947547913,\n",
       "   0.5209000110626221,\n",
       "   0.5213000178337097,\n",
       "   0.5257999897003174,\n",
       "   0.5184999704360962]},\n",
       " 'exp-lr-0.001-opt-Adagrad': {'train-loss': [1.9899206479644775,\n",
       "   1.8002877059173583,\n",
       "   1.7276161730194093,\n",
       "   1.6776052936172485,\n",
       "   1.6416949630737305,\n",
       "   1.610816141281128,\n",
       "   1.5866659402465821,\n",
       "   1.566645156326294,\n",
       "   1.548948253593445,\n",
       "   1.5314607566070557,\n",
       "   1.5170109896469117,\n",
       "   1.502771819152832,\n",
       "   1.4892795016479492,\n",
       "   1.4770459152984619,\n",
       "   1.4662333477401734,\n",
       "   1.4563881764221192,\n",
       "   1.4443690964508056,\n",
       "   1.4351178841781616,\n",
       "   1.42637048828125,\n",
       "   1.4170949090576173,\n",
       "   1.409117661895752,\n",
       "   1.4003054239654542,\n",
       "   1.391942601890564,\n",
       "   1.385309924697876,\n",
       "   1.3766532903289794,\n",
       "   1.3702237115478515,\n",
       "   1.3639683591461182,\n",
       "   1.3562325622558593,\n",
       "   1.3508129466247558,\n",
       "   1.3452357789993286,\n",
       "   1.3397844458770751,\n",
       "   1.3330244232940673,\n",
       "   1.327184460258484,\n",
       "   1.3215795761871338,\n",
       "   1.3151848281478882,\n",
       "   1.3099109301757812,\n",
       "   1.3053910761260987,\n",
       "   1.2998437230682374,\n",
       "   1.2951486614227294,\n",
       "   1.290539853248596,\n",
       "   1.285289829864502,\n",
       "   1.2803863613510131,\n",
       "   1.275700682296753,\n",
       "   1.2707584545516968,\n",
       "   1.267149675064087,\n",
       "   1.262712247543335,\n",
       "   1.2576990725708008,\n",
       "   1.2545568785858154,\n",
       "   1.2492896420288087,\n",
       "   1.245830114517212],\n",
       "  'valid-loss': [1.916089405632019,\n",
       "   1.7819284824371338,\n",
       "   1.738619278717041,\n",
       "   1.685202744102478,\n",
       "   1.6474965385437013,\n",
       "   1.6321843006134034,\n",
       "   1.606152470588684,\n",
       "   1.627440947532654,\n",
       "   1.566835931777954,\n",
       "   1.6159908185958862,\n",
       "   1.5575061241149903,\n",
       "   1.5355065170288087,\n",
       "   1.5219407772064208,\n",
       "   1.5185800212860108,\n",
       "   1.5113624702453614,\n",
       "   1.490485368347168,\n",
       "   1.5064121917724609,\n",
       "   1.495751439666748,\n",
       "   1.488691261291504,\n",
       "   1.4888617233276367,\n",
       "   1.4933927490234375,\n",
       "   1.4653299392700194,\n",
       "   1.4603882381439208,\n",
       "   1.441948662185669,\n",
       "   1.4640574508666993,\n",
       "   1.4410096885681152,\n",
       "   1.468193113708496,\n",
       "   1.4381090490341186,\n",
       "   1.4402432611465454,\n",
       "   1.4332710247039795,\n",
       "   1.4123352012634278,\n",
       "   1.4426214515686036,\n",
       "   1.4720696208953858,\n",
       "   1.4167809692382813,\n",
       "   1.3986391117095947,\n",
       "   1.3921832832336425,\n",
       "   1.4113299467086793,\n",
       "   1.4016199869155883,\n",
       "   1.410419387626648,\n",
       "   1.390507699584961,\n",
       "   1.38874832572937,\n",
       "   1.379122353363037,\n",
       "   1.377516389465332,\n",
       "   1.4048187160491943,\n",
       "   1.4014432386398314,\n",
       "   1.3822048316955566,\n",
       "   1.3968711059570313,\n",
       "   1.3689910564422607,\n",
       "   1.3951617071151734,\n",
       "   1.39512412109375],\n",
       "  'train-acc': [0.28434,\n",
       "   0.36336,\n",
       "   0.39084,\n",
       "   0.40858,\n",
       "   0.4214,\n",
       "   0.4355,\n",
       "   0.442,\n",
       "   0.452,\n",
       "   0.45738,\n",
       "   0.46264,\n",
       "   0.46936,\n",
       "   0.47544,\n",
       "   0.47936,\n",
       "   0.48362,\n",
       "   0.48858,\n",
       "   0.49142,\n",
       "   0.49536,\n",
       "   0.49816,\n",
       "   0.5031,\n",
       "   0.50464,\n",
       "   0.50738,\n",
       "   0.51202,\n",
       "   0.51368,\n",
       "   0.51688,\n",
       "   0.52066,\n",
       "   0.52176,\n",
       "   0.52624,\n",
       "   0.5274,\n",
       "   0.52824,\n",
       "   0.5325,\n",
       "   0.53312,\n",
       "   0.53768,\n",
       "   0.53818,\n",
       "   0.53942,\n",
       "   0.5442,\n",
       "   0.5446,\n",
       "   0.5472,\n",
       "   0.5486,\n",
       "   0.54976,\n",
       "   0.5521,\n",
       "   0.5535,\n",
       "   0.55564,\n",
       "   0.55818,\n",
       "   0.55876,\n",
       "   0.5599,\n",
       "   0.56142,\n",
       "   0.56444,\n",
       "   0.56558,\n",
       "   0.56666,\n",
       "   0.56898],\n",
       "  'valid-acc': [0.2913999855518341,\n",
       "   0.35089999437332153,\n",
       "   0.37720000743865967,\n",
       "   0.3986999988555908,\n",
       "   0.41760000586509705,\n",
       "   0.423799991607666,\n",
       "   0.428600013256073,\n",
       "   0.4226999878883362,\n",
       "   0.45190000534057617,\n",
       "   0.42669999599456787,\n",
       "   0.446399986743927,\n",
       "   0.45879998803138733,\n",
       "   0.46059998869895935,\n",
       "   0.4641000032424927,\n",
       "   0.4724999964237213,\n",
       "   0.4754999876022339,\n",
       "   0.46889999508857727,\n",
       "   0.47099998593330383,\n",
       "   0.4747999906539917,\n",
       "   0.4699999988079071,\n",
       "   0.46549999713897705,\n",
       "   0.4819999933242798,\n",
       "   0.4794999957084656,\n",
       "   0.48739999532699585,\n",
       "   0.484499990940094,\n",
       "   0.48579999804496765,\n",
       "   0.4715000092983246,\n",
       "   0.489300012588501,\n",
       "   0.49239999055862427,\n",
       "   0.48570001125335693,\n",
       "   0.4961000084877014,\n",
       "   0.4846000075340271,\n",
       "   0.48429998755455017,\n",
       "   0.4970000088214874,\n",
       "   0.5055000185966492,\n",
       "   0.5076000094413757,\n",
       "   0.49129998683929443,\n",
       "   0.5048999786376953,\n",
       "   0.49459999799728394,\n",
       "   0.5073000192642212,\n",
       "   0.5095999836921692,\n",
       "   0.5108000040054321,\n",
       "   0.512499988079071,\n",
       "   0.5002999901771545,\n",
       "   0.5029000043869019,\n",
       "   0.5055999755859375,\n",
       "   0.5055999755859375,\n",
       "   0.5162000060081482,\n",
       "   0.5074999928474426,\n",
       "   0.5076000094413757]},\n",
       " 'exp-lr-0.1-opt-Adam': {'train-loss': [353.4188885258484,\n",
       "   2.304777049560547,\n",
       "   2.304220279388428,\n",
       "   2.3046935830688478,\n",
       "   2.3044779875183106,\n",
       "   2.3052912994384767,\n",
       "   2.3058976377105713,\n",
       "   2.305819260635376,\n",
       "   2.3055143495941164,\n",
       "   2.307067305755615,\n",
       "   2.306117997894287,\n",
       "   2.3056047943115234,\n",
       "   2.3060586998748778,\n",
       "   2.306206167755127,\n",
       "   2.3065155516052247,\n",
       "   2.3064138790130615,\n",
       "   2.3072284437561037,\n",
       "   2.306765620803833,\n",
       "   2.3061883447265625,\n",
       "   2.3070487449645998,\n",
       "   2.3067491679382326,\n",
       "   2.3069500085449217,\n",
       "   2.306518462677002,\n",
       "   2.306991880645752,\n",
       "   2.3067321532440186,\n",
       "   2.3068892280578615,\n",
       "   2.305932823638916,\n",
       "   2.3075326158905027,\n",
       "   2.30647493057251,\n",
       "   2.3070409407043457,\n",
       "   2.307476312942505,\n",
       "   2.3066969686889647,\n",
       "   2.306778369140625,\n",
       "   2.3067724897766113,\n",
       "   2.306842677459717,\n",
       "   2.3075523993682863,\n",
       "   2.308166272125244,\n",
       "   2.3069011233520507,\n",
       "   2.307107557525635,\n",
       "   2.306425696487427,\n",
       "   2.307322254867554,\n",
       "   2.3067217028808593,\n",
       "   2.306558946609497,\n",
       "   2.307369862976074,\n",
       "   2.3066090171051026,\n",
       "   2.3066615048217773,\n",
       "   2.3069196365356444,\n",
       "   2.3069024047088624,\n",
       "   2.3061863452911378,\n",
       "   2.3066998844146727],\n",
       "  'valid-loss': [2.3057667472839354,\n",
       "   2.3134545776367186,\n",
       "   2.3147021255493163,\n",
       "   2.3146094848632814,\n",
       "   2.315316952896118,\n",
       "   2.3186518955230713,\n",
       "   2.31597599029541,\n",
       "   2.3148785167694093,\n",
       "   2.3188606704711914,\n",
       "   2.317476205444336,\n",
       "   2.3148743240356446,\n",
       "   2.3167132369995116,\n",
       "   2.313948728179932,\n",
       "   2.316538812637329,\n",
       "   2.317271166610718,\n",
       "   2.3202930351257325,\n",
       "   2.316918022918701,\n",
       "   2.3156583808898925,\n",
       "   2.322510230255127,\n",
       "   2.31817445602417,\n",
       "   2.3154665718078613,\n",
       "   2.3167235828399657,\n",
       "   2.3169444732666014,\n",
       "   2.316623062133789,\n",
       "   2.314967990112305,\n",
       "   2.3148912635803223,\n",
       "   2.3163336601257325,\n",
       "   2.317048038101196,\n",
       "   2.319495319366455,\n",
       "   2.318710845565796,\n",
       "   2.3157323699951173,\n",
       "   2.3142256729125976,\n",
       "   2.316623833847046,\n",
       "   2.315374535369873,\n",
       "   2.3168555210113526,\n",
       "   2.3150961338043214,\n",
       "   2.3171040756225585,\n",
       "   2.319486667251587,\n",
       "   2.317437754058838,\n",
       "   2.3181027893066406,\n",
       "   2.317417589187622,\n",
       "   2.314389268875122,\n",
       "   2.315304917907715,\n",
       "   2.314730316925049,\n",
       "   2.3188240741729738,\n",
       "   2.3183847873687746,\n",
       "   2.316522922515869,\n",
       "   2.317464544677734,\n",
       "   2.3183749828338622,\n",
       "   2.314806902694702],\n",
       "  'train-acc': [0.09928,\n",
       "   0.1021,\n",
       "   0.10006,\n",
       "   0.10048,\n",
       "   0.10172,\n",
       "   0.09732,\n",
       "   0.09958,\n",
       "   0.10024,\n",
       "   0.09816,\n",
       "   0.0981,\n",
       "   0.0969,\n",
       "   0.09878,\n",
       "   0.10162,\n",
       "   0.09988,\n",
       "   0.1012,\n",
       "   0.10228,\n",
       "   0.09966,\n",
       "   0.1005,\n",
       "   0.10102,\n",
       "   0.09968,\n",
       "   0.10088,\n",
       "   0.10014,\n",
       "   0.10048,\n",
       "   0.09906,\n",
       "   0.1,\n",
       "   0.09948,\n",
       "   0.09846,\n",
       "   0.09966,\n",
       "   0.09884,\n",
       "   0.09896,\n",
       "   0.0998,\n",
       "   0.09956,\n",
       "   0.09968,\n",
       "   0.10062,\n",
       "   0.09938,\n",
       "   0.09966,\n",
       "   0.1011,\n",
       "   0.09784,\n",
       "   0.09954,\n",
       "   0.1002,\n",
       "   0.10078,\n",
       "   0.09942,\n",
       "   0.09686,\n",
       "   0.09862,\n",
       "   0.10002,\n",
       "   0.10052,\n",
       "   0.10054,\n",
       "   0.1021,\n",
       "   0.09964,\n",
       "   0.10148],\n",
       "  'valid-acc': [0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.09989999979734421,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.09989999979734421,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.09989999979734421,\n",
       "   0.09989999979734421,\n",
       "   0.10000000149011612,\n",
       "   0.09989999979734421,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.10000000149011612,\n",
       "   0.09989999979734421,\n",
       "   0.09989999979734421]},\n",
       " 'exp-lr-0.01-opt-Adam': {'train-loss': [3.228068980026245,\n",
       "   1.8240963170623778,\n",
       "   1.7666775135040282,\n",
       "   1.7187085479736328,\n",
       "   1.6837236455535889,\n",
       "   1.6557631872177123,\n",
       "   1.643692395095825,\n",
       "   1.6212828204345704,\n",
       "   1.6321749168777466,\n",
       "   1.610242532348633,\n",
       "   1.5925471826934814,\n",
       "   1.6000012085723876,\n",
       "   1.5841603659057617,\n",
       "   1.5790722269439696,\n",
       "   1.581785823173523,\n",
       "   1.5708764190673827,\n",
       "   1.5724477628326416,\n",
       "   1.5675481037521362,\n",
       "   1.568908999710083,\n",
       "   1.568832319908142,\n",
       "   1.5557888318252564,\n",
       "   1.5592799173355103,\n",
       "   1.5575711979293823,\n",
       "   1.5582510746002198,\n",
       "   1.5606765784072876,\n",
       "   1.5439307571411134,\n",
       "   1.5529443842697144,\n",
       "   1.5493253142166137,\n",
       "   1.5475548625946045,\n",
       "   1.5547837897491454,\n",
       "   1.556520130996704,\n",
       "   1.5543628792572022,\n",
       "   1.5484620177841186,\n",
       "   1.543085195274353,\n",
       "   1.5497217791748046,\n",
       "   1.5477854913711548,\n",
       "   1.5507554176712035,\n",
       "   1.5530985988998414,\n",
       "   1.5393963877105712,\n",
       "   1.5409769440078736,\n",
       "   1.5407694792938234,\n",
       "   1.5303552686309814,\n",
       "   1.5536108248519898,\n",
       "   1.5353329920578003,\n",
       "   1.541444606781006,\n",
       "   1.5345662384796142,\n",
       "   1.5328949294281007,\n",
       "   1.5328184408187866,\n",
       "   1.5394383172225952,\n",
       "   1.5424649072647094],\n",
       "  'valid-loss': [1.8784158727645874,\n",
       "   1.7816632125854492,\n",
       "   1.7493101987838746,\n",
       "   1.702554635620117,\n",
       "   1.6644170335769652,\n",
       "   1.6491807613372802,\n",
       "   1.6320788761138916,\n",
       "   1.6679111644744873,\n",
       "   1.6787414539337158,\n",
       "   1.6448715377807617,\n",
       "   1.6458561496734618,\n",
       "   1.5766623069763184,\n",
       "   1.5754323696136474,\n",
       "   1.6123677753448487,\n",
       "   1.648787600326538,\n",
       "   1.6523118915557862,\n",
       "   1.6302381059646607,\n",
       "   1.5930827102661134,\n",
       "   1.623369326210022,\n",
       "   1.5893170486450194,\n",
       "   1.597060315322876,\n",
       "   1.616656960105896,\n",
       "   1.5847908098220824,\n",
       "   1.6634881504058838,\n",
       "   1.5867396335601807,\n",
       "   1.5662119869232178,\n",
       "   1.6242589374542236,\n",
       "   1.571904561805725,\n",
       "   1.612464444732666,\n",
       "   1.6205451919555665,\n",
       "   1.6613983394622802,\n",
       "   1.6404448648452759,\n",
       "   1.6354270887374878,\n",
       "   1.7037567655563355,\n",
       "   1.5795958053588868,\n",
       "   1.6895894063949586,\n",
       "   1.6542131340026855,\n",
       "   1.6328058929443359,\n",
       "   1.6133018566131592,\n",
       "   1.6274836757659912,\n",
       "   1.6163519695281983,\n",
       "   1.6638655021667481,\n",
       "   1.590313784790039,\n",
       "   1.5901509704589845,\n",
       "   1.630388224029541,\n",
       "   1.6525558074951172,\n",
       "   1.6228469848632812,\n",
       "   1.5983756481170655,\n",
       "   1.6042647365570069,\n",
       "   1.7249639919281006],\n",
       "  'train-acc': [0.2335,\n",
       "   0.33672,\n",
       "   0.36078,\n",
       "   0.37858,\n",
       "   0.3922,\n",
       "   0.40506,\n",
       "   0.40642,\n",
       "   0.41476,\n",
       "   0.41228,\n",
       "   0.41938,\n",
       "   0.42568,\n",
       "   0.42546,\n",
       "   0.42732,\n",
       "   0.42804,\n",
       "   0.42716,\n",
       "   0.43276,\n",
       "   0.43186,\n",
       "   0.43528,\n",
       "   0.43506,\n",
       "   0.43318,\n",
       "   0.43772,\n",
       "   0.43768,\n",
       "   0.43536,\n",
       "   0.43798,\n",
       "   0.43566,\n",
       "   0.43936,\n",
       "   0.43514,\n",
       "   0.44222,\n",
       "   0.4428,\n",
       "   0.43804,\n",
       "   0.44194,\n",
       "   0.4342,\n",
       "   0.44192,\n",
       "   0.44246,\n",
       "   0.44108,\n",
       "   0.44128,\n",
       "   0.441,\n",
       "   0.44138,\n",
       "   0.44364,\n",
       "   0.44492,\n",
       "   0.44216,\n",
       "   0.44816,\n",
       "   0.44008,\n",
       "   0.4463,\n",
       "   0.44358,\n",
       "   0.44816,\n",
       "   0.44866,\n",
       "   0.44722,\n",
       "   0.44592,\n",
       "   0.4464],\n",
       "  'valid-acc': [0.31220000982284546,\n",
       "   0.3555000126361847,\n",
       "   0.359499990940094,\n",
       "   0.3788999915122986,\n",
       "   0.39959999918937683,\n",
       "   0.4023999869823456,\n",
       "   0.41659998893737793,\n",
       "   0.3977000117301941,\n",
       "   0.392300009727478,\n",
       "   0.4032000005245209,\n",
       "   0.40950000286102295,\n",
       "   0.43810001015663147,\n",
       "   0.43309998512268066,\n",
       "   0.4253000020980835,\n",
       "   0.41119998693466187,\n",
       "   0.40869998931884766,\n",
       "   0.4165000021457672,\n",
       "   0.4293000102043152,\n",
       "   0.4172999858856201,\n",
       "   0.4375999867916107,\n",
       "   0.4311999976634979,\n",
       "   0.41760000586509705,\n",
       "   0.42980000376701355,\n",
       "   0.4025999903678894,\n",
       "   0.43290001153945923,\n",
       "   0.43209999799728394,\n",
       "   0.4108999967575073,\n",
       "   0.42969998717308044,\n",
       "   0.42660000920295715,\n",
       "   0.4194999933242798,\n",
       "   0.4027000069618225,\n",
       "   0.41029998660087585,\n",
       "   0.41530001163482666,\n",
       "   0.40230000019073486,\n",
       "   0.43369999527931213,\n",
       "   0.39430001378059387,\n",
       "   0.4146000146865845,\n",
       "   0.4239000082015991,\n",
       "   0.41819998621940613,\n",
       "   0.4212999939918518,\n",
       "   0.41350001096725464,\n",
       "   0.4140999913215637,\n",
       "   0.43149998784065247,\n",
       "   0.42899999022483826,\n",
       "   0.4162999987602234,\n",
       "   0.4122999906539917,\n",
       "   0.42640000581741333,\n",
       "   0.42989999055862427,\n",
       "   0.42820000648498535,\n",
       "   0.39399999380111694]},\n",
       " 'exp-lr-0.001-opt-Adam': {'train-loss': [1.9163660891342162,\n",
       "   1.6890410582733155,\n",
       "   1.6015017782974243,\n",
       "   1.5407830208206177,\n",
       "   1.504473341369629,\n",
       "   1.4556333574676514,\n",
       "   1.425008666305542,\n",
       "   1.3975534267425538,\n",
       "   1.3676803441238403,\n",
       "   1.3434513390731813,\n",
       "   1.3088592099761962,\n",
       "   1.289626901473999,\n",
       "   1.2669705910873412,\n",
       "   1.2540252754974366,\n",
       "   1.2281368564224242,\n",
       "   1.2127693990325927,\n",
       "   1.1821562702178956,\n",
       "   1.1639920990753174,\n",
       "   1.1406699237823485,\n",
       "   1.1180391977119446,\n",
       "   1.0986596369934083,\n",
       "   1.0676679125595092,\n",
       "   1.0614830591201783,\n",
       "   1.0367199547958375,\n",
       "   1.0176446162605286,\n",
       "   0.9970763635444642,\n",
       "   0.9883354986190795,\n",
       "   0.9603141684150696,\n",
       "   0.9482754419708253,\n",
       "   0.9300108947753907,\n",
       "   0.9003703760147095,\n",
       "   0.8873334721374512,\n",
       "   0.8672603354263305,\n",
       "   0.8571129788970947,\n",
       "   0.8366450448799133,\n",
       "   0.8118022653007507,\n",
       "   0.8013399911499024,\n",
       "   0.7880118362426758,\n",
       "   0.7660462910270691,\n",
       "   0.7640627212333679,\n",
       "   0.7422418761825561,\n",
       "   0.7146232250976563,\n",
       "   0.7086274402236938,\n",
       "   0.6960341700553894,\n",
       "   0.6934910080337524,\n",
       "   0.6636557734489441,\n",
       "   0.6426579701423645,\n",
       "   0.6415688074111938,\n",
       "   0.6254125413894653,\n",
       "   0.620360237236023],\n",
       "  'valid-loss': [1.7220399583816528,\n",
       "   1.607691125869751,\n",
       "   1.5765671226501465,\n",
       "   1.555248085784912,\n",
       "   1.4971443929672241,\n",
       "   1.4792364444732666,\n",
       "   1.4658697498321533,\n",
       "   1.4660576236724854,\n",
       "   1.4574487873077393,\n",
       "   1.4361040983200073,\n",
       "   1.3985765466690063,\n",
       "   1.3800999969482421,\n",
       "   1.3964878261566163,\n",
       "   1.3650414756774902,\n",
       "   1.3908210147857667,\n",
       "   1.3721149007797242,\n",
       "   1.3571711887359619,\n",
       "   1.3771684833526612,\n",
       "   1.3729321353912354,\n",
       "   1.3709106588363646,\n",
       "   1.4179329772949218,\n",
       "   1.4035736541748047,\n",
       "   1.3848303756713867,\n",
       "   1.37220101852417,\n",
       "   1.408615113067627,\n",
       "   1.4100372735977174,\n",
       "   1.414047313117981,\n",
       "   1.434350980758667,\n",
       "   1.4190165117263793,\n",
       "   1.4509439107894897,\n",
       "   1.4548965782165528,\n",
       "   1.5111723163604736,\n",
       "   1.5215571451187133,\n",
       "   1.4892030599594117,\n",
       "   1.5259372554779054,\n",
       "   1.5281826803207397,\n",
       "   1.598717145729065,\n",
       "   1.5726565744400025,\n",
       "   1.5524316780090333,\n",
       "   1.604259358215332,\n",
       "   1.6066128479003907,\n",
       "   1.611064779663086,\n",
       "   1.6322040397644042,\n",
       "   1.6701416107177733,\n",
       "   1.7227457704544067,\n",
       "   1.8068114425659179,\n",
       "   1.782753875732422,\n",
       "   1.7699558471679688,\n",
       "   1.8224152896881103,\n",
       "   1.8345199279785156],\n",
       "  'train-acc': [0.31018,\n",
       "   0.39466,\n",
       "   0.42704,\n",
       "   0.45034,\n",
       "   0.46408,\n",
       "   0.48164,\n",
       "   0.49116,\n",
       "   0.50182,\n",
       "   0.51104,\n",
       "   0.52084,\n",
       "   0.53524,\n",
       "   0.54002,\n",
       "   0.547,\n",
       "   0.55302,\n",
       "   0.56234,\n",
       "   0.56714,\n",
       "   0.5778,\n",
       "   0.58514,\n",
       "   0.59386,\n",
       "   0.6026,\n",
       "   0.60696,\n",
       "   0.61874,\n",
       "   0.62232,\n",
       "   0.63104,\n",
       "   0.63722,\n",
       "   0.64396,\n",
       "   0.64642,\n",
       "   0.65794,\n",
       "   0.6592,\n",
       "   0.66844,\n",
       "   0.68162,\n",
       "   0.68334,\n",
       "   0.68892,\n",
       "   0.69286,\n",
       "   0.70262,\n",
       "   0.71022,\n",
       "   0.7144,\n",
       "   0.7172,\n",
       "   0.72732,\n",
       "   0.7289,\n",
       "   0.73518,\n",
       "   0.74522,\n",
       "   0.74632,\n",
       "   0.75168,\n",
       "   0.75348,\n",
       "   0.76344,\n",
       "   0.77036,\n",
       "   0.76986,\n",
       "   0.77672,\n",
       "   0.77768],\n",
       "  'valid-acc': [0.3801000118255615,\n",
       "   0.42750000953674316,\n",
       "   0.43779999017715454,\n",
       "   0.44609999656677246,\n",
       "   0.4666000008583069,\n",
       "   0.4697999954223633,\n",
       "   0.4749000072479248,\n",
       "   0.486299991607666,\n",
       "   0.4876999855041504,\n",
       "   0.4941999912261963,\n",
       "   0.4984000027179718,\n",
       "   0.5095000267028809,\n",
       "   0.5067999958992004,\n",
       "   0.5192000269889832,\n",
       "   0.5091000199317932,\n",
       "   0.5188000202178955,\n",
       "   0.5274999737739563,\n",
       "   0.519599974155426,\n",
       "   0.5163999795913696,\n",
       "   0.5252000093460083,\n",
       "   0.5123999714851379,\n",
       "   0.5123999714851379,\n",
       "   0.5185999870300293,\n",
       "   0.5332000255584717,\n",
       "   0.519599974155426,\n",
       "   0.5260999798774719,\n",
       "   0.5170999765396118,\n",
       "   0.5250999927520752,\n",
       "   0.524399995803833,\n",
       "   0.5202999711036682,\n",
       "   0.5246999859809875,\n",
       "   0.5171999931335449,\n",
       "   0.5102999806404114,\n",
       "   0.526199996471405,\n",
       "   0.5217999815940857,\n",
       "   0.5238999724388123,\n",
       "   0.5157999992370605,\n",
       "   0.5218999981880188,\n",
       "   0.513700008392334,\n",
       "   0.5250999927520752,\n",
       "   0.5254999995231628,\n",
       "   0.5235000252723694,\n",
       "   0.5174999833106995,\n",
       "   0.5164999961853027,\n",
       "   0.5120999813079834,\n",
       "   0.512499988079071,\n",
       "   0.5135999917984009,\n",
       "   0.5156000256538391,\n",
       "   0.5216000080108643,\n",
       "   0.519599974155426]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "plt.figure(figsize=(8, 6))\n",
    "opt_all = ['SGD', 'RMSprop', 'Adagrad', 'Adam']\n",
    "\n",
    "for i, opt in enumerate(opt_all):\n",
    "    cond = \"exp-lr-0.001-opt-\"+opt\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond+\"-val\", color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, opt in enumerate(opt_all):\n",
    "    cond = \"exp-lr-0.001-opt-\"+opt\n",
    "    plt.plot(range(len(results[cond]['train-acc'])), results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])), results[cond]['valid-acc'], '--', label=cond+\"-val\", color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['exp-lr-0.1-opt-SGD', 'exp-lr-0.01-opt-SGD', 'exp-lr-0.001-opt-SGD', 'exp-lr-0.1-opt-RMSprop', 'exp-lr-0.01-opt-RMSprop', 'exp-lr-0.001-opt-RMSprop', 'exp-lr-0.1-opt-Adagrad', 'exp-lr-0.01-opt-Adagrad', 'exp-lr-0.001-opt-Adagrad', 'exp-lr-0.1-opt-Adam', 'exp-lr-0.01-opt-Adam', 'exp-lr-0.001-opt-Adam'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input optimizers: (SGD/RMSprop/Adagrad/Adam)RMSprop\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-80902df50014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mopt_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please input optimizers: (SGD/RMSprop/Adagrad/Adam)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcolor_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"g\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 0.1 難收斂！\n",
    "opt_select = input('Please input optimizers: (SGD/RMSprop/Adagrad/Adam)')\n",
    "color_bar = [\"r\", \"g\", \"b\"]\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, lr in enumerate(LEARNING_RATE):\n",
    "    cond = \"exp-lr-\"+str(lr)+\"-opt-\"+ opt_select\n",
    "    plt.plot(range(len(results[cond][\"train-loss\"])), results[cond][\"train-loss\"], '-', label=cond, c=color_bar[i])\n",
    "    plt.plot(range(len(results[cond][\"valid-loss\"])), results[cond][\"valid-loss\"], '--', label=cond+'-val', c=color_bar[i])\n",
    "plt.title('Loss')\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, lr in enumerate(LEARNING_RATE):\n",
    "    cond = \"exp-lr-\"+str(lr)+\"-opt-\" + opt_select\n",
    "    plt.plot(range(len(results[cond][\"train-acc\"])), results[cond][\"train-acc\"], '-', label=cond, c=color_bar[i])\n",
    "    plt.plot(range(len(results[cond][\"valid-acc\"])), results[cond][\"valid-acc\"], '--', label=cond+'-val', c=color_bar[i])\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
